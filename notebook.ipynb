{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'ldm' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n ldm ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch import autocast\n",
    "from einops import rearrange\n",
    "\n",
    "from stablediffusion.ldm.models.diffusion.ddim import DDIMSampler\n",
    "from stablediffusion.ldm.models.diffusion.plms import PLMSSampler\n",
    "from stablediffusion.scripts.txt2img import load_model_from_config\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "prompt_i = \"a painting of a virus monster playing guitar\"\n",
    "prompt_j = \"a forested landscape\"\n",
    "\n",
    "w_i = 0.5\n",
    "w_j = 0.5\n",
    "\n",
    "config = \"stablediffusion/configs/latent-diffusion/txt2img-1p4B-eval.yaml\"\n",
    "\n",
    "timesteps = 1000\n",
    "\n",
    "n = 1 # Number of samples / batch size\n",
    "ch = 4 # Latent channels\n",
    "f = 8 # Downsample factor\n",
    "h = 512 # Image height\n",
    "w = 512 # Image width\n",
    "\n",
    "scale = 7.5 # Unconditional guidance scale\n",
    "ddim_eta = 0.0 # 0.0 corresponds to deterministic sampling\n",
    "shape = [ch, h // f, w // f]\n",
    "\n",
    "b = n\n",
    "\n",
    "model = load_model_from_config(config, 'sd-v2-1.ckpt')\n",
    "model = model.to(device)\n",
    "model = PLMSSampler(model)\n",
    "\n",
    "with torch.no_grad():\n",
    "    with autocast('cuda'):\n",
    "        with model.ema_scope():\n",
    "            uc = model.get_learned_conditioning(n * [\"\"])\n",
    "            c_i = model.get_learned_conditioning(n * [prompt_i])\n",
    "            c_j = model.get_learned_conditioning(n * [prompt_j])\n",
    "\n",
    "@torch.no_grad()\n",
    "def p_sample(model, x, c, ts, index, old_eps=None, t_next=None):\n",
    "    outs = model.p_sample_plms(x, c, ts, index=index, unconditional_guidance_scale=scale, unconditional_conditioning=uc,)\n",
    "    x, _, e_t = outs\n",
    "    old_eps.append(e_t)\n",
    "    if len(old_eps) >= 4:\n",
    "        old_eps.pop(0)\n",
    "\n",
    "    return old_eps \n",
    "\n",
    "with torch.no_grad():\n",
    "    with autocast('cuda'):\n",
    "        with model.ema_scope():\n",
    "            # Initialize sample x_T to N(0,I)\n",
    "            x = torch.randn((n, ch, h // f, w // f)).to(device)\n",
    "\n",
    "            model.make_schedule(ddim_num_steps=timesteps, ddim_eta=ddim_eta, verbose=False)\n",
    "            timesteps = model.ddim_timesteps\n",
    "            time_range = np.flip(timesteps)\n",
    "            total_steps = timesteps.shape[0]\n",
    "            e_ti = []\n",
    "            e_tj = []\n",
    "            for i, step in enumerate(tqdm(time_range, desc='PLMS Sampler', total=total_steps)):\n",
    "                index = total_steps - i - 1\n",
    "                ts = torch.full((b,), step, device=device, dtype=torch.long)\n",
    "                ts_next = torch.full((b,), time_range[min(i + 1, len(time_range) - 1)], device=device, dtype=torch.long)\n",
    "                \n",
    "                # Compute conditional scores for each concept c_i\n",
    "                e_ti = p_sample(model, x, c_i, ts, index, e_ti, ts_next) \n",
    "                e_tj = p_sample(model, x, c_j, ts, index, e_tj, ts_next)\n",
    "                e_i = e_ti[-1]\n",
    "                e_j = e_tj[-1]\n",
    "\n",
    "                # Compute unconditional score\n",
    "                e_t = p_sample(model, x, uc, ts, index, e_t, ts_next)\n",
    "                e = e_t[-1]\n",
    "                \n",
    "                # Sampling\n",
    "                mean = x - (e + w_i * (e_i - e) + w_j * (e_j - e))\n",
    "                covar = model.betas[ts]\n",
    "                x = torch.normal(mean, covar*torch.eye(h // f, w // f)) # Sampling\n",
    "\n",
    "            x = model.decode_first_stage([x])\n",
    "            x = torch.clamp((x + 1.0) / 2.0, min=0.0, max=1.0)\n",
    "\n",
    "            count = 0\n",
    "            for sample in x:\n",
    "                sample = 255 * rearrange(sample.cpu().numpy(), 'c h w -> h w c')\n",
    "                img = Image.fromarray(sample.astype(np.uint8))\n",
    "                img.save(os.path.join(sample_path, f\"output_{count}.png\"))\n",
    "                count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
