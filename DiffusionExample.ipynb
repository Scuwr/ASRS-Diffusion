{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec77a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b77963c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(PARAMETERS=None, NUM_WORKERS=0, BATCH_SIZE=2, MAX_NUM_WORDS=64, IMG_SIDE_LEN=128, EPOCHS=5, T5_NAME='t5_base', TRAIN_VALID_FRAC=0.9, TIMESTEPS=1000, OPTIM_LR=0.0001, ACCUM_ITER=1, CHCKPT_NUM=500, VALID_NUM=None, RESTART_DIRECTORY=None, TESTING=False, timestamp=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: conceptual_captions/unlabeled\n",
      "Found cached dataset conceptual_captions (/afs/csail.mit.edu/u/c/cmarnold/.cache/huggingface/datasets/conceptual_captions/unlabeled/1.0.0/05266784888422e36944016874c44639bccb39069c2227435168ad8b02d600d8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7cce34090744ef8c728192dd020ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas:\n",
      "\ttensor([0.0001, 0.0001, 0.0001, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0003,\n",
      "        0.0003, 0.0003, 0.0003, 0.0003, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004,\n",
      "        0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0006, 0.0006, 0.0006, 0.0006,\n",
      "        0.0006, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0008, 0.0008, 0.0008,\n",
      "        0.0008, 0.0008, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0010, 0.0010,\n",
      "        0.0010, 0.0010, 0.0010, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0012,\n",
      "        0.0012, 0.0012, 0.0012, 0.0012, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013,\n",
      "        0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0015, 0.0015, 0.0015, 0.0015,\n",
      "        0.0015, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0017, 0.0017, 0.0017,\n",
      "        0.0017, 0.0017, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0019, 0.0019,\n",
      "        0.0019, 0.0019, 0.0019, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0021,\n",
      "        0.0021, 0.0021, 0.0021, 0.0021, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022,\n",
      "        0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0024, 0.0024, 0.0024, 0.0024,\n",
      "        0.0024, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0026, 0.0026, 0.0026,\n",
      "        0.0026, 0.0026, 0.0026, 0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0028,\n",
      "        0.0028, 0.0028, 0.0028, 0.0028, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029,\n",
      "        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0031, 0.0031, 0.0031, 0.0031,\n",
      "        0.0031, 0.0032, 0.0032, 0.0032, 0.0032, 0.0032, 0.0033, 0.0033, 0.0033,\n",
      "        0.0033, 0.0033, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0035, 0.0035,\n",
      "        0.0035, 0.0035, 0.0035, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0037,\n",
      "        0.0037, 0.0037, 0.0037, 0.0037, 0.0038, 0.0038, 0.0038, 0.0038, 0.0038,\n",
      "        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "        0.0040, 0.0041, 0.0041, 0.0041, 0.0041, 0.0041, 0.0042, 0.0042, 0.0042,\n",
      "        0.0042, 0.0042, 0.0043, 0.0043, 0.0043, 0.0043, 0.0043, 0.0044, 0.0044,\n",
      "        0.0044, 0.0044, 0.0044, 0.0045, 0.0045, 0.0045, 0.0045, 0.0045, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0047, 0.0047, 0.0047, 0.0047, 0.0047,\n",
      "        0.0048, 0.0048, 0.0048, 0.0048, 0.0048, 0.0049, 0.0049, 0.0049, 0.0049,\n",
      "        0.0049, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0051, 0.0051, 0.0051,\n",
      "        0.0051, 0.0051, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0053, 0.0053,\n",
      "        0.0053, 0.0053, 0.0053, 0.0054, 0.0054, 0.0054, 0.0054, 0.0054, 0.0055,\n",
      "        0.0055, 0.0055, 0.0055, 0.0055, 0.0056, 0.0056, 0.0056, 0.0056, 0.0056,\n",
      "        0.0057, 0.0057, 0.0057, 0.0057, 0.0057, 0.0058, 0.0058, 0.0058, 0.0058,\n",
      "        0.0058, 0.0059, 0.0059, 0.0059, 0.0059, 0.0059, 0.0060, 0.0060, 0.0060,\n",
      "        0.0060, 0.0060, 0.0061, 0.0061, 0.0061, 0.0061, 0.0061, 0.0062, 0.0062,\n",
      "        0.0062, 0.0062, 0.0062, 0.0063, 0.0063, 0.0063, 0.0063, 0.0063, 0.0064,\n",
      "        0.0064, 0.0064, 0.0064, 0.0064, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065,\n",
      "        0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0067, 0.0067, 0.0067, 0.0067,\n",
      "        0.0067, 0.0068, 0.0068, 0.0068, 0.0068, 0.0068, 0.0069, 0.0069, 0.0069,\n",
      "        0.0069, 0.0069, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0071, 0.0071,\n",
      "        0.0071, 0.0071, 0.0071, 0.0072, 0.0072, 0.0072, 0.0072, 0.0072, 0.0073,\n",
      "        0.0073, 0.0073, 0.0073, 0.0073, 0.0074, 0.0074, 0.0074, 0.0074, 0.0074,\n",
      "        0.0075, 0.0075, 0.0075, 0.0075, 0.0075, 0.0076, 0.0076, 0.0076, 0.0076,\n",
      "        0.0076, 0.0076, 0.0077, 0.0077, 0.0077, 0.0077, 0.0077, 0.0078, 0.0078,\n",
      "        0.0078, 0.0078, 0.0078, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0080,\n",
      "        0.0080, 0.0080, 0.0080, 0.0080, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0082, 0.0082, 0.0082, 0.0082, 0.0082, 0.0083, 0.0083, 0.0083, 0.0083,\n",
      "        0.0083, 0.0084, 0.0084, 0.0084, 0.0084, 0.0084, 0.0085, 0.0085, 0.0085,\n",
      "        0.0085, 0.0085, 0.0086, 0.0086, 0.0086, 0.0086, 0.0086, 0.0087, 0.0087,\n",
      "        0.0087, 0.0087, 0.0087, 0.0088, 0.0088, 0.0088, 0.0088, 0.0088, 0.0089,\n",
      "        0.0089, 0.0089, 0.0089, 0.0089, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0092, 0.0092, 0.0092, 0.0092,\n",
      "        0.0092, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0094, 0.0094, 0.0094,\n",
      "        0.0094, 0.0094, 0.0095, 0.0095, 0.0095, 0.0095, 0.0095, 0.0096, 0.0096,\n",
      "        0.0096, 0.0096, 0.0096, 0.0097, 0.0097, 0.0097, 0.0097, 0.0097, 0.0098,\n",
      "        0.0098, 0.0098, 0.0098, 0.0098, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0101, 0.0101, 0.0101, 0.0101,\n",
      "        0.0101, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0103, 0.0103, 0.0103,\n",
      "        0.0103, 0.0103, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0105, 0.0105,\n",
      "        0.0105, 0.0105, 0.0105, 0.0106, 0.0106, 0.0106, 0.0106, 0.0106, 0.0107,\n",
      "        0.0107, 0.0107, 0.0107, 0.0107, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108,\n",
      "        0.0109, 0.0109, 0.0109, 0.0109, 0.0109, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "        0.0110, 0.0111, 0.0111, 0.0111, 0.0111, 0.0111, 0.0112, 0.0112, 0.0112,\n",
      "        0.0112, 0.0112, 0.0113, 0.0113, 0.0113, 0.0113, 0.0113, 0.0114, 0.0114,\n",
      "        0.0114, 0.0114, 0.0114, 0.0115, 0.0115, 0.0115, 0.0115, 0.0115, 0.0116,\n",
      "        0.0116, 0.0116, 0.0116, 0.0116, 0.0117, 0.0117, 0.0117, 0.0117, 0.0117,\n",
      "        0.0118, 0.0118, 0.0118, 0.0118, 0.0118, 0.0119, 0.0119, 0.0119, 0.0119,\n",
      "        0.0119, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0121, 0.0121, 0.0121,\n",
      "        0.0121, 0.0121, 0.0122, 0.0122, 0.0122, 0.0122, 0.0122, 0.0123, 0.0123,\n",
      "        0.0123, 0.0123, 0.0123, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0125,\n",
      "        0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0126, 0.0126, 0.0126, 0.0126,\n",
      "        0.0126, 0.0127, 0.0127, 0.0127, 0.0127, 0.0127, 0.0128, 0.0128, 0.0128,\n",
      "        0.0128, 0.0128, 0.0129, 0.0129, 0.0129, 0.0129, 0.0129, 0.0130, 0.0130,\n",
      "        0.0130, 0.0130, 0.0130, 0.0131, 0.0131, 0.0131, 0.0131, 0.0131, 0.0132,\n",
      "        0.0132, 0.0132, 0.0132, 0.0132, 0.0133, 0.0133, 0.0133, 0.0133, 0.0133,\n",
      "        0.0134, 0.0134, 0.0134, 0.0134, 0.0134, 0.0135, 0.0135, 0.0135, 0.0135,\n",
      "        0.0135, 0.0136, 0.0136, 0.0136, 0.0136, 0.0136, 0.0137, 0.0137, 0.0137,\n",
      "        0.0137, 0.0137, 0.0138, 0.0138, 0.0138, 0.0138, 0.0138, 0.0139, 0.0139,\n",
      "        0.0139, 0.0139, 0.0139, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0141,\n",
      "        0.0141, 0.0141, 0.0141, 0.0141, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
      "        0.0143, 0.0143, 0.0143, 0.0143, 0.0143, 0.0144, 0.0144, 0.0144, 0.0144,\n",
      "        0.0144, 0.0145, 0.0145, 0.0145, 0.0145, 0.0145, 0.0146, 0.0146, 0.0146,\n",
      "        0.0146, 0.0146, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0148, 0.0148,\n",
      "        0.0148, 0.0148, 0.0148, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0150,\n",
      "        0.0150, 0.0150, 0.0150, 0.0150, 0.0151, 0.0151, 0.0151, 0.0151, 0.0151,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0153, 0.0153, 0.0153, 0.0153,\n",
      "        0.0153, 0.0154, 0.0154, 0.0154, 0.0154, 0.0154, 0.0155, 0.0155, 0.0155,\n",
      "        0.0155, 0.0155, 0.0156, 0.0156, 0.0156, 0.0156, 0.0156, 0.0157, 0.0157,\n",
      "        0.0157, 0.0157, 0.0157, 0.0158, 0.0158, 0.0158, 0.0158, 0.0158, 0.0159,\n",
      "        0.0159, 0.0159, 0.0159, 0.0159, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "        0.0161, 0.0161, 0.0161, 0.0161, 0.0161, 0.0162, 0.0162, 0.0162, 0.0162,\n",
      "        0.0162, 0.0163, 0.0163, 0.0163, 0.0163, 0.0163, 0.0164, 0.0164, 0.0164,\n",
      "        0.0164, 0.0164, 0.0165, 0.0165, 0.0165, 0.0165, 0.0165, 0.0166, 0.0166,\n",
      "        0.0166, 0.0166, 0.0166, 0.0167, 0.0167, 0.0167, 0.0167, 0.0167, 0.0168,\n",
      "        0.0168, 0.0168, 0.0168, 0.0168, 0.0169, 0.0169, 0.0169, 0.0169, 0.0169,\n",
      "        0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0171, 0.0171, 0.0171, 0.0171,\n",
      "        0.0171, 0.0172, 0.0172, 0.0172, 0.0172, 0.0172, 0.0173, 0.0173, 0.0173,\n",
      "        0.0173, 0.0173, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0175, 0.0175,\n",
      "        0.0175, 0.0175, 0.0175, 0.0175, 0.0176, 0.0176, 0.0176, 0.0176, 0.0176,\n",
      "        0.0177, 0.0177, 0.0177, 0.0177, 0.0177, 0.0178, 0.0178, 0.0178, 0.0178,\n",
      "        0.0178, 0.0179, 0.0179, 0.0179, 0.0179, 0.0179, 0.0180, 0.0180, 0.0180,\n",
      "        0.0180, 0.0180, 0.0181, 0.0181, 0.0181, 0.0181, 0.0181, 0.0182, 0.0182,\n",
      "        0.0182, 0.0182, 0.0182, 0.0183, 0.0183, 0.0183, 0.0183, 0.0183, 0.0184,\n",
      "        0.0184, 0.0184, 0.0184, 0.0184, 0.0185, 0.0185, 0.0185, 0.0185, 0.0185,\n",
      "        0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0187, 0.0187, 0.0187, 0.0187,\n",
      "        0.0187, 0.0188, 0.0188, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189,\n",
      "        0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0191, 0.0191,\n",
      "        0.0191, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0192, 0.0192, 0.0193,\n",
      "        0.0193, 0.0193, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194,\n",
      "        0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0198, 0.0198, 0.0198,\n",
      "        0.0198, 0.0198, 0.0199, 0.0199, 0.0199, 0.0199, 0.0199, 0.0200, 0.0200,\n",
      "        0.0200], dtype=torch.float64)\n",
      "alphas_cumprod:\n",
      "\ttensor([9.9990e-01, 9.9978e-01, 9.9964e-01, 9.9948e-01, 9.9930e-01, 9.9910e-01,\n",
      "        9.9888e-01, 9.9864e-01, 9.9838e-01, 9.9811e-01, 9.9781e-01, 9.9749e-01,\n",
      "        9.9715e-01, 9.9679e-01, 9.9641e-01, 9.9602e-01, 9.9560e-01, 9.9516e-01,\n",
      "        9.9471e-01, 9.9423e-01, 9.9374e-01, 9.9322e-01, 9.9269e-01, 9.9213e-01,\n",
      "        9.9156e-01, 9.9097e-01, 9.9035e-01, 9.8972e-01, 9.8907e-01, 9.8840e-01,\n",
      "        9.8771e-01, 9.8700e-01, 9.8627e-01, 9.8553e-01, 9.8476e-01, 9.8398e-01,\n",
      "        9.8317e-01, 9.8235e-01, 9.8151e-01, 9.8065e-01, 9.7977e-01, 9.7887e-01,\n",
      "        9.7795e-01, 9.7702e-01, 9.7606e-01, 9.7509e-01, 9.7410e-01, 9.7309e-01,\n",
      "        9.7206e-01, 9.7102e-01, 9.6995e-01, 9.6887e-01, 9.6777e-01, 9.6665e-01,\n",
      "        9.6551e-01, 9.6436e-01, 9.6319e-01, 9.6200e-01, 9.6079e-01, 9.5956e-01,\n",
      "        9.5832e-01, 9.5706e-01, 9.5578e-01, 9.5449e-01, 9.5318e-01, 9.5185e-01,\n",
      "        9.5050e-01, 9.4914e-01, 9.4776e-01, 9.4636e-01, 9.4494e-01, 9.4351e-01,\n",
      "        9.4207e-01, 9.4060e-01, 9.3912e-01, 9.3762e-01, 9.3611e-01, 9.3458e-01,\n",
      "        9.3304e-01, 9.3147e-01, 9.2990e-01, 9.2830e-01, 9.2669e-01, 9.2507e-01,\n",
      "        9.2343e-01, 9.2177e-01, 9.2010e-01, 9.1842e-01, 9.1671e-01, 9.1500e-01,\n",
      "        9.1326e-01, 9.1152e-01, 9.0976e-01, 9.0798e-01, 9.0619e-01, 9.0438e-01,\n",
      "        9.0256e-01, 9.0073e-01, 8.9888e-01, 8.9702e-01, 8.9514e-01, 8.9325e-01,\n",
      "        8.9135e-01, 8.8943e-01, 8.8750e-01, 8.8555e-01, 8.8359e-01, 8.8162e-01,\n",
      "        8.7964e-01, 8.7764e-01, 8.7563e-01, 8.7360e-01, 8.7157e-01, 8.6952e-01,\n",
      "        8.6746e-01, 8.6538e-01, 8.6330e-01, 8.6120e-01, 8.5909e-01, 8.5697e-01,\n",
      "        8.5483e-01, 8.5269e-01, 8.5053e-01, 8.4836e-01, 8.4618e-01, 8.4399e-01,\n",
      "        8.4179e-01, 8.3957e-01, 8.3735e-01, 8.3511e-01, 8.3287e-01, 8.3061e-01,\n",
      "        8.2834e-01, 8.2606e-01, 8.2378e-01, 8.2148e-01, 8.1917e-01, 8.1685e-01,\n",
      "        8.1453e-01, 8.1219e-01, 8.0984e-01, 8.0749e-01, 8.0512e-01, 8.0275e-01,\n",
      "        8.0037e-01, 7.9797e-01, 7.9557e-01, 7.9317e-01, 7.9075e-01, 7.8832e-01,\n",
      "        7.8589e-01, 7.8344e-01, 7.8099e-01, 7.7854e-01, 7.7607e-01, 7.7360e-01,\n",
      "        7.7111e-01, 7.6863e-01, 7.6613e-01, 7.6363e-01, 7.6112e-01, 7.5860e-01,\n",
      "        7.5608e-01, 7.5354e-01, 7.5101e-01, 7.4846e-01, 7.4591e-01, 7.4336e-01,\n",
      "        7.4080e-01, 7.3823e-01, 7.3565e-01, 7.3308e-01, 7.3049e-01, 7.2790e-01,\n",
      "        7.2530e-01, 7.2270e-01, 7.2010e-01, 7.1749e-01, 7.1487e-01, 7.1225e-01,\n",
      "        7.0963e-01, 7.0700e-01, 7.0436e-01, 7.0172e-01, 6.9908e-01, 6.9644e-01,\n",
      "        6.9379e-01, 6.9113e-01, 6.8847e-01, 6.8581e-01, 6.8315e-01, 6.8048e-01,\n",
      "        6.7781e-01, 6.7514e-01, 6.7246e-01, 6.6978e-01, 6.6710e-01, 6.6441e-01,\n",
      "        6.6173e-01, 6.5904e-01, 6.5635e-01, 6.5365e-01, 6.5096e-01, 6.4826e-01,\n",
      "        6.4556e-01, 6.4286e-01, 6.4016e-01, 6.3745e-01, 6.3475e-01, 6.3204e-01,\n",
      "        6.2934e-01, 6.2663e-01, 6.2392e-01, 6.2121e-01, 6.1850e-01, 6.1579e-01,\n",
      "        6.1308e-01, 6.1037e-01, 6.0765e-01, 6.0494e-01, 6.0223e-01, 5.9952e-01,\n",
      "        5.9681e-01, 5.9410e-01, 5.9139e-01, 5.8868e-01, 5.8597e-01, 5.8326e-01,\n",
      "        5.8055e-01, 5.7785e-01, 5.7514e-01, 5.7244e-01, 5.6974e-01, 5.6703e-01,\n",
      "        5.6433e-01, 5.6164e-01, 5.5894e-01, 5.5624e-01, 5.5355e-01, 5.5086e-01,\n",
      "        5.4817e-01, 5.4549e-01, 5.4280e-01, 5.4012e-01, 5.3744e-01, 5.3476e-01,\n",
      "        5.3209e-01, 5.2942e-01, 5.2675e-01, 5.2409e-01, 5.2142e-01, 5.1876e-01,\n",
      "        5.1611e-01, 5.1346e-01, 5.1081e-01, 5.0816e-01, 5.0552e-01, 5.0288e-01,\n",
      "        5.0024e-01, 4.9761e-01, 4.9499e-01, 4.9236e-01, 4.8974e-01, 4.8713e-01,\n",
      "        4.8452e-01, 4.8191e-01, 4.7931e-01, 4.7671e-01, 4.7412e-01, 4.7153e-01,\n",
      "        4.6895e-01, 4.6637e-01, 4.6380e-01, 4.6123e-01, 4.5867e-01, 4.5611e-01,\n",
      "        4.5356e-01, 4.5101e-01, 4.4846e-01, 4.4593e-01, 4.4340e-01, 4.4087e-01,\n",
      "        4.3835e-01, 4.3583e-01, 4.3332e-01, 4.3082e-01, 4.2832e-01, 4.2583e-01,\n",
      "        4.2335e-01, 4.2087e-01, 4.1839e-01, 4.1593e-01, 4.1347e-01, 4.1101e-01,\n",
      "        4.0856e-01, 4.0612e-01, 4.0369e-01, 4.0126e-01, 3.9884e-01, 3.9642e-01,\n",
      "        3.9401e-01, 3.9161e-01, 3.8921e-01, 3.8683e-01, 3.8444e-01, 3.8207e-01,\n",
      "        3.7970e-01, 3.7734e-01, 3.7499e-01, 3.7265e-01, 3.7031e-01, 3.6798e-01,\n",
      "        3.6565e-01, 3.6334e-01, 3.6103e-01, 3.5873e-01, 3.5643e-01, 3.5414e-01,\n",
      "        3.5187e-01, 3.4959e-01, 3.4733e-01, 3.4508e-01, 3.4283e-01, 3.4059e-01,\n",
      "        3.3836e-01, 3.3613e-01, 3.3391e-01, 3.3171e-01, 3.2951e-01, 3.2731e-01,\n",
      "        3.2513e-01, 3.2295e-01, 3.2078e-01, 3.1862e-01, 3.1647e-01, 3.1433e-01,\n",
      "        3.1219e-01, 3.1007e-01, 3.0795e-01, 3.0584e-01, 3.0374e-01, 3.0164e-01,\n",
      "        2.9956e-01, 2.9748e-01, 2.9541e-01, 2.9335e-01, 2.9130e-01, 2.8926e-01,\n",
      "        2.8723e-01, 2.8520e-01, 2.8318e-01, 2.8117e-01, 2.7917e-01, 2.7718e-01,\n",
      "        2.7520e-01, 2.7323e-01, 2.7126e-01, 2.6931e-01, 2.6736e-01, 2.6542e-01,\n",
      "        2.6349e-01, 2.6157e-01, 2.5966e-01, 2.5775e-01, 2.5586e-01, 2.5397e-01,\n",
      "        2.5210e-01, 2.5023e-01, 2.4837e-01, 2.4652e-01, 2.4468e-01, 2.4284e-01,\n",
      "        2.4102e-01, 2.3920e-01, 2.3740e-01, 2.3560e-01, 2.3381e-01, 2.3203e-01,\n",
      "        2.3026e-01, 2.2850e-01, 2.2675e-01, 2.2501e-01, 2.2327e-01, 2.2155e-01,\n",
      "        2.1983e-01, 2.1812e-01, 2.1642e-01, 2.1473e-01, 2.1305e-01, 2.1138e-01,\n",
      "        2.0972e-01, 2.0806e-01, 2.0642e-01, 2.0478e-01, 2.0315e-01, 2.0153e-01,\n",
      "        1.9992e-01, 1.9832e-01, 1.9673e-01, 1.9515e-01, 1.9357e-01, 1.9201e-01,\n",
      "        1.9045e-01, 1.8890e-01, 1.8736e-01, 1.8583e-01, 1.8431e-01, 1.8280e-01,\n",
      "        1.8129e-01, 1.7980e-01, 1.7831e-01, 1.7683e-01, 1.7537e-01, 1.7391e-01,\n",
      "        1.7245e-01, 1.7101e-01, 1.6958e-01, 1.6815e-01, 1.6673e-01, 1.6533e-01,\n",
      "        1.6393e-01, 1.6254e-01, 1.6115e-01, 1.5978e-01, 1.5841e-01, 1.5706e-01,\n",
      "        1.5571e-01, 1.5437e-01, 1.5304e-01, 1.5171e-01, 1.5040e-01, 1.4909e-01,\n",
      "        1.4779e-01, 1.4650e-01, 1.4522e-01, 1.4395e-01, 1.4269e-01, 1.4143e-01,\n",
      "        1.4018e-01, 1.3894e-01, 1.3771e-01, 1.3649e-01, 1.3527e-01, 1.3406e-01,\n",
      "        1.3286e-01, 1.3167e-01, 1.3049e-01, 1.2932e-01, 1.2815e-01, 1.2699e-01,\n",
      "        1.2584e-01, 1.2470e-01, 1.2356e-01, 1.2243e-01, 1.2131e-01, 1.2020e-01,\n",
      "        1.1910e-01, 1.1800e-01, 1.1691e-01, 1.1583e-01, 1.1476e-01, 1.1369e-01,\n",
      "        1.1264e-01, 1.1159e-01, 1.1054e-01, 1.0951e-01, 1.0848e-01, 1.0746e-01,\n",
      "        1.0645e-01, 1.0544e-01, 1.0445e-01, 1.0346e-01, 1.0247e-01, 1.0150e-01,\n",
      "        1.0053e-01, 9.9567e-02, 9.8613e-02, 9.7667e-02, 9.6727e-02, 9.5794e-02,\n",
      "        9.4869e-02, 9.3950e-02, 9.3039e-02, 9.2134e-02, 9.1237e-02, 9.0346e-02,\n",
      "        8.9463e-02, 8.8586e-02, 8.7716e-02, 8.6853e-02, 8.5996e-02, 8.5146e-02,\n",
      "        8.4303e-02, 8.3467e-02, 8.2637e-02, 8.1814e-02, 8.0998e-02, 8.0188e-02,\n",
      "        7.9384e-02, 7.8587e-02, 7.7797e-02, 7.7012e-02, 7.6235e-02, 7.5463e-02,\n",
      "        7.4698e-02, 7.3939e-02, 7.3186e-02, 7.2440e-02, 7.1700e-02, 7.0966e-02,\n",
      "        7.0238e-02, 6.9516e-02, 6.8800e-02, 6.8090e-02, 6.7386e-02, 6.6688e-02,\n",
      "        6.5996e-02, 6.5309e-02, 6.4629e-02, 6.3954e-02, 6.3285e-02, 6.2622e-02,\n",
      "        6.1965e-02, 6.1313e-02, 6.0667e-02, 6.0026e-02, 5.9391e-02, 5.8762e-02,\n",
      "        5.8138e-02, 5.7520e-02, 5.6907e-02, 5.6299e-02, 5.5697e-02, 5.5100e-02,\n",
      "        5.4508e-02, 5.3922e-02, 5.3341e-02, 5.2765e-02, 5.2194e-02, 5.1628e-02,\n",
      "        5.1068e-02, 5.0513e-02, 4.9962e-02, 4.9417e-02, 4.8876e-02, 4.8341e-02,\n",
      "        4.7810e-02, 4.7284e-02, 4.6764e-02, 4.6247e-02, 4.5736e-02, 4.5230e-02,\n",
      "        4.4728e-02, 4.4231e-02, 4.3738e-02, 4.3250e-02, 4.2767e-02, 4.2288e-02,\n",
      "        4.1814e-02, 4.1344e-02, 4.0879e-02, 4.0418e-02, 3.9961e-02, 3.9509e-02,\n",
      "        3.9061e-02, 3.8618e-02, 3.8178e-02, 3.7743e-02, 3.7312e-02, 3.6886e-02,\n",
      "        3.6463e-02, 3.6045e-02, 3.5631e-02, 3.5220e-02, 3.4814e-02, 3.4412e-02,\n",
      "        3.4014e-02, 3.3619e-02, 3.3229e-02, 3.2842e-02, 3.2460e-02, 3.2081e-02,\n",
      "        3.1705e-02, 3.1334e-02, 3.0966e-02, 3.0603e-02, 3.0242e-02, 2.9886e-02,\n",
      "        2.9533e-02, 2.9183e-02, 2.8837e-02, 2.8495e-02, 2.8156e-02, 2.7821e-02,\n",
      "        2.7489e-02, 2.7160e-02, 2.6835e-02, 2.6513e-02, 2.6195e-02, 2.5879e-02,\n",
      "        2.5567e-02, 2.5259e-02, 2.4953e-02, 2.4651e-02, 2.4352e-02, 2.4056e-02,\n",
      "        2.3763e-02, 2.3474e-02, 2.3187e-02, 2.2903e-02, 2.2623e-02, 2.2345e-02,\n",
      "        2.2071e-02, 2.1799e-02, 2.1530e-02, 2.1264e-02, 2.1001e-02, 2.0741e-02,\n",
      "        2.0484e-02, 2.0229e-02, 1.9977e-02, 1.9728e-02, 1.9482e-02, 1.9238e-02,\n",
      "        1.8997e-02, 1.8758e-02, 1.8523e-02, 1.8289e-02, 1.8059e-02, 1.7831e-02,\n",
      "        1.7605e-02, 1.7382e-02, 1.7161e-02, 1.6943e-02, 1.6728e-02, 1.6514e-02,\n",
      "        1.6304e-02, 1.6095e-02, 1.5889e-02, 1.5685e-02, 1.5484e-02, 1.5284e-02,\n",
      "        1.5087e-02, 1.4893e-02, 1.4700e-02, 1.4510e-02, 1.4321e-02, 1.4135e-02,\n",
      "        1.3952e-02, 1.3770e-02, 1.3590e-02, 1.3413e-02, 1.3237e-02, 1.3064e-02,\n",
      "        1.2892e-02, 1.2723e-02, 1.2555e-02, 1.2389e-02, 1.2226e-02, 1.2064e-02,\n",
      "        1.1904e-02, 1.1746e-02, 1.1590e-02, 1.1436e-02, 1.1284e-02, 1.1133e-02,\n",
      "        1.0984e-02, 1.0837e-02, 1.0692e-02, 1.0548e-02, 1.0407e-02, 1.0266e-02,\n",
      "        1.0128e-02, 9.9911e-03, 9.8560e-03, 9.7225e-03, 9.5906e-03, 9.4603e-03,\n",
      "        9.3316e-03, 9.2044e-03, 9.0788e-03, 8.9548e-03, 8.8322e-03, 8.7112e-03,\n",
      "        8.5916e-03, 8.4735e-03, 8.3569e-03, 8.2417e-03, 8.1279e-03, 8.0155e-03,\n",
      "        7.9046e-03, 7.7950e-03, 7.6867e-03, 7.5799e-03, 7.4743e-03, 7.3701e-03,\n",
      "        7.2672e-03, 7.1655e-03, 7.0652e-03, 6.9661e-03, 6.8683e-03, 6.7717e-03,\n",
      "        6.6763e-03, 6.5822e-03, 6.4892e-03, 6.3974e-03, 6.3068e-03, 6.2173e-03,\n",
      "        6.1290e-03, 6.0419e-03, 5.9558e-03, 5.8709e-03, 5.7870e-03, 5.7042e-03,\n",
      "        5.6225e-03, 5.5419e-03, 5.4623e-03, 5.3837e-03, 5.3062e-03, 5.2297e-03,\n",
      "        5.1541e-03, 5.0796e-03, 5.0060e-03, 4.9334e-03, 4.8618e-03, 4.7911e-03,\n",
      "        4.7213e-03, 4.6525e-03, 4.5845e-03, 4.5175e-03, 4.4514e-03, 4.3861e-03,\n",
      "        4.3217e-03, 4.2582e-03, 4.1955e-03, 4.1336e-03, 4.0726e-03, 4.0124e-03,\n",
      "        3.9530e-03, 3.8945e-03, 3.8367e-03, 3.7796e-03, 3.7234e-03, 3.6679e-03,\n",
      "        3.6132e-03, 3.5592e-03, 3.5060e-03, 3.4534e-03, 3.4016e-03, 3.3506e-03,\n",
      "        3.3002e-03, 3.2505e-03, 3.2014e-03, 3.1531e-03, 3.1054e-03, 3.0584e-03,\n",
      "        3.0120e-03, 2.9663e-03, 2.9212e-03, 2.8768e-03, 2.8329e-03, 2.7897e-03,\n",
      "        2.7471e-03, 2.7051e-03, 2.6636e-03, 2.6228e-03, 2.5825e-03, 2.5428e-03,\n",
      "        2.5036e-03, 2.4650e-03, 2.4270e-03, 2.3894e-03, 2.3525e-03, 2.3160e-03,\n",
      "        2.2801e-03, 2.2446e-03, 2.2097e-03, 2.1753e-03, 2.1414e-03, 2.1079e-03,\n",
      "        2.0750e-03, 2.0425e-03, 2.0104e-03, 1.9789e-03, 1.9478e-03, 1.9171e-03,\n",
      "        1.8869e-03, 1.8572e-03, 1.8278e-03, 1.7989e-03, 1.7704e-03, 1.7423e-03,\n",
      "        1.7147e-03, 1.6874e-03, 1.6606e-03, 1.6341e-03, 1.6080e-03, 1.5823e-03,\n",
      "        1.5570e-03, 1.5321e-03, 1.5075e-03, 1.4833e-03, 1.4595e-03, 1.4360e-03,\n",
      "        1.4128e-03, 1.3900e-03, 1.3676e-03, 1.3455e-03, 1.3237e-03, 1.3022e-03,\n",
      "        1.2811e-03, 1.2602e-03, 1.2397e-03, 1.2195e-03, 1.1996e-03, 1.1800e-03,\n",
      "        1.1607e-03, 1.1417e-03, 1.1230e-03, 1.1046e-03, 1.0864e-03, 1.0686e-03,\n",
      "        1.0509e-03, 1.0336e-03, 1.0165e-03, 9.9974e-04, 9.8319e-04, 9.6689e-04,\n",
      "        9.5085e-04, 9.3505e-04, 9.1950e-04, 9.0419e-04, 8.8911e-04, 8.7427e-04,\n",
      "        8.5966e-04, 8.4527e-04, 8.3111e-04, 8.1717e-04, 8.0345e-04, 7.8994e-04,\n",
      "        7.7664e-04, 7.6355e-04, 7.5067e-04, 7.3799e-04, 7.2551e-04, 7.1322e-04,\n",
      "        7.0113e-04, 6.8923e-04, 6.7752e-04, 6.6600e-04, 6.5465e-04, 6.4349e-04,\n",
      "        6.3250e-04, 6.2169e-04, 6.1106e-04, 6.0059e-04, 5.9029e-04, 5.8015e-04,\n",
      "        5.7018e-04, 5.6036e-04, 5.5071e-04, 5.4121e-04, 5.3186e-04, 5.2266e-04,\n",
      "        5.1362e-04, 5.0472e-04, 4.9596e-04, 4.8734e-04, 4.7887e-04, 4.7053e-04,\n",
      "        4.6233e-04, 4.5426e-04, 4.4633e-04, 4.3852e-04, 4.3084e-04, 4.2329e-04,\n",
      "        4.1586e-04, 4.0855e-04, 4.0137e-04, 3.9430e-04, 3.8735e-04, 3.8051e-04,\n",
      "        3.7379e-04, 3.6718e-04, 3.6067e-04, 3.5428e-04, 3.4799e-04, 3.4181e-04,\n",
      "        3.3573e-04, 3.2975e-04, 3.2387e-04, 3.1809e-04, 3.1240e-04, 3.0682e-04,\n",
      "        3.0132e-04, 2.9592e-04, 2.9061e-04, 2.8539e-04, 2.8025e-04, 2.7521e-04,\n",
      "        2.7024e-04, 2.6537e-04, 2.6057e-04, 2.5586e-04, 2.5123e-04, 2.4667e-04,\n",
      "        2.4220e-04, 2.3780e-04, 2.3347e-04, 2.2922e-04, 2.2504e-04, 2.2094e-04,\n",
      "        2.1690e-04, 2.1293e-04, 2.0904e-04, 2.0520e-04, 2.0144e-04, 1.9774e-04,\n",
      "        1.9410e-04, 1.9053e-04, 1.8702e-04, 1.8357e-04, 1.8018e-04, 1.7685e-04,\n",
      "        1.7358e-04, 1.7036e-04, 1.6720e-04, 1.6410e-04, 1.6105e-04, 1.5805e-04,\n",
      "        1.5511e-04, 1.5222e-04, 1.4937e-04, 1.4658e-04, 1.4384e-04, 1.4115e-04,\n",
      "        1.3850e-04, 1.3590e-04, 1.3335e-04, 1.3084e-04, 1.2838e-04, 1.2596e-04,\n",
      "        1.2358e-04, 1.2125e-04, 1.1896e-04, 1.1671e-04, 1.1450e-04, 1.1232e-04,\n",
      "        1.1019e-04, 1.0810e-04, 1.0604e-04, 1.0402e-04, 1.0204e-04, 1.0009e-04,\n",
      "        9.8180e-05, 9.6302e-05, 9.4459e-05, 9.2649e-05, 9.0871e-05, 8.9126e-05,\n",
      "        8.7413e-05, 8.5731e-05, 8.4080e-05, 8.2458e-05, 8.0867e-05, 7.9304e-05,\n",
      "        7.7770e-05, 7.6264e-05, 7.4786e-05, 7.3335e-05, 7.1911e-05, 7.0513e-05,\n",
      "        6.9140e-05, 6.7793e-05, 6.6471e-05, 6.5173e-05, 6.3900e-05, 6.2650e-05,\n",
      "        6.1423e-05, 6.0219e-05, 5.9038e-05, 5.7878e-05, 5.6740e-05, 5.5623e-05,\n",
      "        5.4527e-05, 5.3452e-05, 5.2397e-05, 5.1361e-05, 5.0345e-05, 4.9349e-05,\n",
      "        4.8370e-05, 4.7411e-05, 4.6469e-05, 4.5545e-05, 4.4639e-05, 4.3750e-05,\n",
      "        4.2877e-05, 4.2022e-05, 4.1182e-05, 4.0358e-05], dtype=torch.float64)\n",
      "betas:\n",
      "\ttensor([0.0001, 0.0001, 0.0001, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0003,\n",
      "        0.0003, 0.0003, 0.0003, 0.0003, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004,\n",
      "        0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0006, 0.0006, 0.0006, 0.0006,\n",
      "        0.0006, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0008, 0.0008, 0.0008,\n",
      "        0.0008, 0.0008, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0010, 0.0010,\n",
      "        0.0010, 0.0010, 0.0010, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0012,\n",
      "        0.0012, 0.0012, 0.0012, 0.0012, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013,\n",
      "        0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0015, 0.0015, 0.0015, 0.0015,\n",
      "        0.0015, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0017, 0.0017, 0.0017,\n",
      "        0.0017, 0.0017, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0019, 0.0019,\n",
      "        0.0019, 0.0019, 0.0019, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0021,\n",
      "        0.0021, 0.0021, 0.0021, 0.0021, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022,\n",
      "        0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0024, 0.0024, 0.0024, 0.0024,\n",
      "        0.0024, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0026, 0.0026, 0.0026,\n",
      "        0.0026, 0.0026, 0.0026, 0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0028,\n",
      "        0.0028, 0.0028, 0.0028, 0.0028, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029,\n",
      "        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0031, 0.0031, 0.0031, 0.0031,\n",
      "        0.0031, 0.0032, 0.0032, 0.0032, 0.0032, 0.0032, 0.0033, 0.0033, 0.0033,\n",
      "        0.0033, 0.0033, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0035, 0.0035,\n",
      "        0.0035, 0.0035, 0.0035, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0037,\n",
      "        0.0037, 0.0037, 0.0037, 0.0037, 0.0038, 0.0038, 0.0038, 0.0038, 0.0038,\n",
      "        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "        0.0040, 0.0041, 0.0041, 0.0041, 0.0041, 0.0041, 0.0042, 0.0042, 0.0042,\n",
      "        0.0042, 0.0042, 0.0043, 0.0043, 0.0043, 0.0043, 0.0043, 0.0044, 0.0044,\n",
      "        0.0044, 0.0044, 0.0044, 0.0045, 0.0045, 0.0045, 0.0045, 0.0045, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0047, 0.0047, 0.0047, 0.0047, 0.0047,\n",
      "        0.0048, 0.0048, 0.0048, 0.0048, 0.0048, 0.0049, 0.0049, 0.0049, 0.0049,\n",
      "        0.0049, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0051, 0.0051, 0.0051,\n",
      "        0.0051, 0.0051, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0053, 0.0053,\n",
      "        0.0053, 0.0053, 0.0053, 0.0054, 0.0054, 0.0054, 0.0054, 0.0054, 0.0055,\n",
      "        0.0055, 0.0055, 0.0055, 0.0055, 0.0056, 0.0056, 0.0056, 0.0056, 0.0056,\n",
      "        0.0057, 0.0057, 0.0057, 0.0057, 0.0057, 0.0058, 0.0058, 0.0058, 0.0058,\n",
      "        0.0058, 0.0059, 0.0059, 0.0059, 0.0059, 0.0059, 0.0060, 0.0060, 0.0060,\n",
      "        0.0060, 0.0060, 0.0061, 0.0061, 0.0061, 0.0061, 0.0061, 0.0062, 0.0062,\n",
      "        0.0062, 0.0062, 0.0062, 0.0063, 0.0063, 0.0063, 0.0063, 0.0063, 0.0064,\n",
      "        0.0064, 0.0064, 0.0064, 0.0064, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065,\n",
      "        0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0067, 0.0067, 0.0067, 0.0067,\n",
      "        0.0067, 0.0068, 0.0068, 0.0068, 0.0068, 0.0068, 0.0069, 0.0069, 0.0069,\n",
      "        0.0069, 0.0069, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0071, 0.0071,\n",
      "        0.0071, 0.0071, 0.0071, 0.0072, 0.0072, 0.0072, 0.0072, 0.0072, 0.0073,\n",
      "        0.0073, 0.0073, 0.0073, 0.0073, 0.0074, 0.0074, 0.0074, 0.0074, 0.0074,\n",
      "        0.0075, 0.0075, 0.0075, 0.0075, 0.0075, 0.0076, 0.0076, 0.0076, 0.0076,\n",
      "        0.0076, 0.0076, 0.0077, 0.0077, 0.0077, 0.0077, 0.0077, 0.0078, 0.0078,\n",
      "        0.0078, 0.0078, 0.0078, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0080,\n",
      "        0.0080, 0.0080, 0.0080, 0.0080, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0082, 0.0082, 0.0082, 0.0082, 0.0082, 0.0083, 0.0083, 0.0083, 0.0083,\n",
      "        0.0083, 0.0084, 0.0084, 0.0084, 0.0084, 0.0084, 0.0085, 0.0085, 0.0085,\n",
      "        0.0085, 0.0085, 0.0086, 0.0086, 0.0086, 0.0086, 0.0086, 0.0087, 0.0087,\n",
      "        0.0087, 0.0087, 0.0087, 0.0088, 0.0088, 0.0088, 0.0088, 0.0088, 0.0089,\n",
      "        0.0089, 0.0089, 0.0089, 0.0089, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0092, 0.0092, 0.0092, 0.0092,\n",
      "        0.0092, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0094, 0.0094, 0.0094,\n",
      "        0.0094, 0.0094, 0.0095, 0.0095, 0.0095, 0.0095, 0.0095, 0.0096, 0.0096,\n",
      "        0.0096, 0.0096, 0.0096, 0.0097, 0.0097, 0.0097, 0.0097, 0.0097, 0.0098,\n",
      "        0.0098, 0.0098, 0.0098, 0.0098, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0101, 0.0101, 0.0101, 0.0101,\n",
      "        0.0101, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0103, 0.0103, 0.0103,\n",
      "        0.0103, 0.0103, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0105, 0.0105,\n",
      "        0.0105, 0.0105, 0.0105, 0.0106, 0.0106, 0.0106, 0.0106, 0.0106, 0.0107,\n",
      "        0.0107, 0.0107, 0.0107, 0.0107, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108,\n",
      "        0.0109, 0.0109, 0.0109, 0.0109, 0.0109, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "        0.0110, 0.0111, 0.0111, 0.0111, 0.0111, 0.0111, 0.0112, 0.0112, 0.0112,\n",
      "        0.0112, 0.0112, 0.0113, 0.0113, 0.0113, 0.0113, 0.0113, 0.0114, 0.0114,\n",
      "        0.0114, 0.0114, 0.0114, 0.0115, 0.0115, 0.0115, 0.0115, 0.0115, 0.0116,\n",
      "        0.0116, 0.0116, 0.0116, 0.0116, 0.0117, 0.0117, 0.0117, 0.0117, 0.0117,\n",
      "        0.0118, 0.0118, 0.0118, 0.0118, 0.0118, 0.0119, 0.0119, 0.0119, 0.0119,\n",
      "        0.0119, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0121, 0.0121, 0.0121,\n",
      "        0.0121, 0.0121, 0.0122, 0.0122, 0.0122, 0.0122, 0.0122, 0.0123, 0.0123,\n",
      "        0.0123, 0.0123, 0.0123, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0125,\n",
      "        0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0126, 0.0126, 0.0126, 0.0126,\n",
      "        0.0126, 0.0127, 0.0127, 0.0127, 0.0127, 0.0127, 0.0128, 0.0128, 0.0128,\n",
      "        0.0128, 0.0128, 0.0129, 0.0129, 0.0129, 0.0129, 0.0129, 0.0130, 0.0130,\n",
      "        0.0130, 0.0130, 0.0130, 0.0131, 0.0131, 0.0131, 0.0131, 0.0131, 0.0132,\n",
      "        0.0132, 0.0132, 0.0132, 0.0132, 0.0133, 0.0133, 0.0133, 0.0133, 0.0133,\n",
      "        0.0134, 0.0134, 0.0134, 0.0134, 0.0134, 0.0135, 0.0135, 0.0135, 0.0135,\n",
      "        0.0135, 0.0136, 0.0136, 0.0136, 0.0136, 0.0136, 0.0137, 0.0137, 0.0137,\n",
      "        0.0137, 0.0137, 0.0138, 0.0138, 0.0138, 0.0138, 0.0138, 0.0139, 0.0139,\n",
      "        0.0139, 0.0139, 0.0139, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0141,\n",
      "        0.0141, 0.0141, 0.0141, 0.0141, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
      "        0.0143, 0.0143, 0.0143, 0.0143, 0.0143, 0.0144, 0.0144, 0.0144, 0.0144,\n",
      "        0.0144, 0.0145, 0.0145, 0.0145, 0.0145, 0.0145, 0.0146, 0.0146, 0.0146,\n",
      "        0.0146, 0.0146, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0148, 0.0148,\n",
      "        0.0148, 0.0148, 0.0148, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0150,\n",
      "        0.0150, 0.0150, 0.0150, 0.0150, 0.0151, 0.0151, 0.0151, 0.0151, 0.0151,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0153, 0.0153, 0.0153, 0.0153,\n",
      "        0.0153, 0.0154, 0.0154, 0.0154, 0.0154, 0.0154, 0.0155, 0.0155, 0.0155,\n",
      "        0.0155, 0.0155, 0.0156, 0.0156, 0.0156, 0.0156, 0.0156, 0.0157, 0.0157,\n",
      "        0.0157, 0.0157, 0.0157, 0.0158, 0.0158, 0.0158, 0.0158, 0.0158, 0.0159,\n",
      "        0.0159, 0.0159, 0.0159, 0.0159, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "        0.0161, 0.0161, 0.0161, 0.0161, 0.0161, 0.0162, 0.0162, 0.0162, 0.0162,\n",
      "        0.0162, 0.0163, 0.0163, 0.0163, 0.0163, 0.0163, 0.0164, 0.0164, 0.0164,\n",
      "        0.0164, 0.0164, 0.0165, 0.0165, 0.0165, 0.0165, 0.0165, 0.0166, 0.0166,\n",
      "        0.0166, 0.0166, 0.0166, 0.0167, 0.0167, 0.0167, 0.0167, 0.0167, 0.0168,\n",
      "        0.0168, 0.0168, 0.0168, 0.0168, 0.0169, 0.0169, 0.0169, 0.0169, 0.0169,\n",
      "        0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0171, 0.0171, 0.0171, 0.0171,\n",
      "        0.0171, 0.0172, 0.0172, 0.0172, 0.0172, 0.0172, 0.0173, 0.0173, 0.0173,\n",
      "        0.0173, 0.0173, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0175, 0.0175,\n",
      "        0.0175, 0.0175, 0.0175, 0.0175, 0.0176, 0.0176, 0.0176, 0.0176, 0.0176,\n",
      "        0.0177, 0.0177, 0.0177, 0.0177, 0.0177, 0.0178, 0.0178, 0.0178, 0.0178,\n",
      "        0.0178, 0.0179, 0.0179, 0.0179, 0.0179, 0.0179, 0.0180, 0.0180, 0.0180,\n",
      "        0.0180, 0.0180, 0.0181, 0.0181, 0.0181, 0.0181, 0.0181, 0.0182, 0.0182,\n",
      "        0.0182, 0.0182, 0.0182, 0.0183, 0.0183, 0.0183, 0.0183, 0.0183, 0.0184,\n",
      "        0.0184, 0.0184, 0.0184, 0.0184, 0.0185, 0.0185, 0.0185, 0.0185, 0.0185,\n",
      "        0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0187, 0.0187, 0.0187, 0.0187,\n",
      "        0.0187, 0.0188, 0.0188, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189,\n",
      "        0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0191, 0.0191,\n",
      "        0.0191, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0192, 0.0192, 0.0193,\n",
      "        0.0193, 0.0193, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194,\n",
      "        0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0198, 0.0198, 0.0198,\n",
      "        0.0198, 0.0198, 0.0199, 0.0199, 0.0199, 0.0199, 0.0199, 0.0200, 0.0200,\n",
      "        0.0200], dtype=torch.float64)\n",
      "alphas_cumprod:\n",
      "\ttensor([9.9990e-01, 9.9978e-01, 9.9964e-01, 9.9948e-01, 9.9930e-01, 9.9910e-01,\n",
      "        9.9888e-01, 9.9864e-01, 9.9838e-01, 9.9811e-01, 9.9781e-01, 9.9749e-01,\n",
      "        9.9715e-01, 9.9679e-01, 9.9641e-01, 9.9602e-01, 9.9560e-01, 9.9516e-01,\n",
      "        9.9471e-01, 9.9423e-01, 9.9374e-01, 9.9322e-01, 9.9269e-01, 9.9213e-01,\n",
      "        9.9156e-01, 9.9097e-01, 9.9035e-01, 9.8972e-01, 9.8907e-01, 9.8840e-01,\n",
      "        9.8771e-01, 9.8700e-01, 9.8627e-01, 9.8553e-01, 9.8476e-01, 9.8398e-01,\n",
      "        9.8317e-01, 9.8235e-01, 9.8151e-01, 9.8065e-01, 9.7977e-01, 9.7887e-01,\n",
      "        9.7795e-01, 9.7702e-01, 9.7606e-01, 9.7509e-01, 9.7410e-01, 9.7309e-01,\n",
      "        9.7206e-01, 9.7102e-01, 9.6995e-01, 9.6887e-01, 9.6777e-01, 9.6665e-01,\n",
      "        9.6551e-01, 9.6436e-01, 9.6319e-01, 9.6200e-01, 9.6079e-01, 9.5956e-01,\n",
      "        9.5832e-01, 9.5706e-01, 9.5578e-01, 9.5449e-01, 9.5318e-01, 9.5185e-01,\n",
      "        9.5050e-01, 9.4914e-01, 9.4776e-01, 9.4636e-01, 9.4494e-01, 9.4351e-01,\n",
      "        9.4207e-01, 9.4060e-01, 9.3912e-01, 9.3762e-01, 9.3611e-01, 9.3458e-01,\n",
      "        9.3304e-01, 9.3147e-01, 9.2990e-01, 9.2830e-01, 9.2669e-01, 9.2507e-01,\n",
      "        9.2343e-01, 9.2177e-01, 9.2010e-01, 9.1842e-01, 9.1671e-01, 9.1500e-01,\n",
      "        9.1326e-01, 9.1152e-01, 9.0976e-01, 9.0798e-01, 9.0619e-01, 9.0438e-01,\n",
      "        9.0256e-01, 9.0073e-01, 8.9888e-01, 8.9702e-01, 8.9514e-01, 8.9325e-01,\n",
      "        8.9135e-01, 8.8943e-01, 8.8750e-01, 8.8555e-01, 8.8359e-01, 8.8162e-01,\n",
      "        8.7964e-01, 8.7764e-01, 8.7563e-01, 8.7360e-01, 8.7157e-01, 8.6952e-01,\n",
      "        8.6746e-01, 8.6538e-01, 8.6330e-01, 8.6120e-01, 8.5909e-01, 8.5697e-01,\n",
      "        8.5483e-01, 8.5269e-01, 8.5053e-01, 8.4836e-01, 8.4618e-01, 8.4399e-01,\n",
      "        8.4179e-01, 8.3957e-01, 8.3735e-01, 8.3511e-01, 8.3287e-01, 8.3061e-01,\n",
      "        8.2834e-01, 8.2606e-01, 8.2378e-01, 8.2148e-01, 8.1917e-01, 8.1685e-01,\n",
      "        8.1453e-01, 8.1219e-01, 8.0984e-01, 8.0749e-01, 8.0512e-01, 8.0275e-01,\n",
      "        8.0037e-01, 7.9797e-01, 7.9557e-01, 7.9317e-01, 7.9075e-01, 7.8832e-01,\n",
      "        7.8589e-01, 7.8344e-01, 7.8099e-01, 7.7854e-01, 7.7607e-01, 7.7360e-01,\n",
      "        7.7111e-01, 7.6863e-01, 7.6613e-01, 7.6363e-01, 7.6112e-01, 7.5860e-01,\n",
      "        7.5608e-01, 7.5354e-01, 7.5101e-01, 7.4846e-01, 7.4591e-01, 7.4336e-01,\n",
      "        7.4080e-01, 7.3823e-01, 7.3565e-01, 7.3308e-01, 7.3049e-01, 7.2790e-01,\n",
      "        7.2530e-01, 7.2270e-01, 7.2010e-01, 7.1749e-01, 7.1487e-01, 7.1225e-01,\n",
      "        7.0963e-01, 7.0700e-01, 7.0436e-01, 7.0172e-01, 6.9908e-01, 6.9644e-01,\n",
      "        6.9379e-01, 6.9113e-01, 6.8847e-01, 6.8581e-01, 6.8315e-01, 6.8048e-01,\n",
      "        6.7781e-01, 6.7514e-01, 6.7246e-01, 6.6978e-01, 6.6710e-01, 6.6441e-01,\n",
      "        6.6173e-01, 6.5904e-01, 6.5635e-01, 6.5365e-01, 6.5096e-01, 6.4826e-01,\n",
      "        6.4556e-01, 6.4286e-01, 6.4016e-01, 6.3745e-01, 6.3475e-01, 6.3204e-01,\n",
      "        6.2934e-01, 6.2663e-01, 6.2392e-01, 6.2121e-01, 6.1850e-01, 6.1579e-01,\n",
      "        6.1308e-01, 6.1037e-01, 6.0765e-01, 6.0494e-01, 6.0223e-01, 5.9952e-01,\n",
      "        5.9681e-01, 5.9410e-01, 5.9139e-01, 5.8868e-01, 5.8597e-01, 5.8326e-01,\n",
      "        5.8055e-01, 5.7785e-01, 5.7514e-01, 5.7244e-01, 5.6974e-01, 5.6703e-01,\n",
      "        5.6433e-01, 5.6164e-01, 5.5894e-01, 5.5624e-01, 5.5355e-01, 5.5086e-01,\n",
      "        5.4817e-01, 5.4549e-01, 5.4280e-01, 5.4012e-01, 5.3744e-01, 5.3476e-01,\n",
      "        5.3209e-01, 5.2942e-01, 5.2675e-01, 5.2409e-01, 5.2142e-01, 5.1876e-01,\n",
      "        5.1611e-01, 5.1346e-01, 5.1081e-01, 5.0816e-01, 5.0552e-01, 5.0288e-01,\n",
      "        5.0024e-01, 4.9761e-01, 4.9499e-01, 4.9236e-01, 4.8974e-01, 4.8713e-01,\n",
      "        4.8452e-01, 4.8191e-01, 4.7931e-01, 4.7671e-01, 4.7412e-01, 4.7153e-01,\n",
      "        4.6895e-01, 4.6637e-01, 4.6380e-01, 4.6123e-01, 4.5867e-01, 4.5611e-01,\n",
      "        4.5356e-01, 4.5101e-01, 4.4846e-01, 4.4593e-01, 4.4340e-01, 4.4087e-01,\n",
      "        4.3835e-01, 4.3583e-01, 4.3332e-01, 4.3082e-01, 4.2832e-01, 4.2583e-01,\n",
      "        4.2335e-01, 4.2087e-01, 4.1839e-01, 4.1593e-01, 4.1347e-01, 4.1101e-01,\n",
      "        4.0856e-01, 4.0612e-01, 4.0369e-01, 4.0126e-01, 3.9884e-01, 3.9642e-01,\n",
      "        3.9401e-01, 3.9161e-01, 3.8921e-01, 3.8683e-01, 3.8444e-01, 3.8207e-01,\n",
      "        3.7970e-01, 3.7734e-01, 3.7499e-01, 3.7265e-01, 3.7031e-01, 3.6798e-01,\n",
      "        3.6565e-01, 3.6334e-01, 3.6103e-01, 3.5873e-01, 3.5643e-01, 3.5414e-01,\n",
      "        3.5187e-01, 3.4959e-01, 3.4733e-01, 3.4508e-01, 3.4283e-01, 3.4059e-01,\n",
      "        3.3836e-01, 3.3613e-01, 3.3391e-01, 3.3171e-01, 3.2951e-01, 3.2731e-01,\n",
      "        3.2513e-01, 3.2295e-01, 3.2078e-01, 3.1862e-01, 3.1647e-01, 3.1433e-01,\n",
      "        3.1219e-01, 3.1007e-01, 3.0795e-01, 3.0584e-01, 3.0374e-01, 3.0164e-01,\n",
      "        2.9956e-01, 2.9748e-01, 2.9541e-01, 2.9335e-01, 2.9130e-01, 2.8926e-01,\n",
      "        2.8723e-01, 2.8520e-01, 2.8318e-01, 2.8117e-01, 2.7917e-01, 2.7718e-01,\n",
      "        2.7520e-01, 2.7323e-01, 2.7126e-01, 2.6931e-01, 2.6736e-01, 2.6542e-01,\n",
      "        2.6349e-01, 2.6157e-01, 2.5966e-01, 2.5775e-01, 2.5586e-01, 2.5397e-01,\n",
      "        2.5210e-01, 2.5023e-01, 2.4837e-01, 2.4652e-01, 2.4468e-01, 2.4284e-01,\n",
      "        2.4102e-01, 2.3920e-01, 2.3740e-01, 2.3560e-01, 2.3381e-01, 2.3203e-01,\n",
      "        2.3026e-01, 2.2850e-01, 2.2675e-01, 2.2501e-01, 2.2327e-01, 2.2155e-01,\n",
      "        2.1983e-01, 2.1812e-01, 2.1642e-01, 2.1473e-01, 2.1305e-01, 2.1138e-01,\n",
      "        2.0972e-01, 2.0806e-01, 2.0642e-01, 2.0478e-01, 2.0315e-01, 2.0153e-01,\n",
      "        1.9992e-01, 1.9832e-01, 1.9673e-01, 1.9515e-01, 1.9357e-01, 1.9201e-01,\n",
      "        1.9045e-01, 1.8890e-01, 1.8736e-01, 1.8583e-01, 1.8431e-01, 1.8280e-01,\n",
      "        1.8129e-01, 1.7980e-01, 1.7831e-01, 1.7683e-01, 1.7537e-01, 1.7391e-01,\n",
      "        1.7245e-01, 1.7101e-01, 1.6958e-01, 1.6815e-01, 1.6673e-01, 1.6533e-01,\n",
      "        1.6393e-01, 1.6254e-01, 1.6115e-01, 1.5978e-01, 1.5841e-01, 1.5706e-01,\n",
      "        1.5571e-01, 1.5437e-01, 1.5304e-01, 1.5171e-01, 1.5040e-01, 1.4909e-01,\n",
      "        1.4779e-01, 1.4650e-01, 1.4522e-01, 1.4395e-01, 1.4269e-01, 1.4143e-01,\n",
      "        1.4018e-01, 1.3894e-01, 1.3771e-01, 1.3649e-01, 1.3527e-01, 1.3406e-01,\n",
      "        1.3286e-01, 1.3167e-01, 1.3049e-01, 1.2932e-01, 1.2815e-01, 1.2699e-01,\n",
      "        1.2584e-01, 1.2470e-01, 1.2356e-01, 1.2243e-01, 1.2131e-01, 1.2020e-01,\n",
      "        1.1910e-01, 1.1800e-01, 1.1691e-01, 1.1583e-01, 1.1476e-01, 1.1369e-01,\n",
      "        1.1264e-01, 1.1159e-01, 1.1054e-01, 1.0951e-01, 1.0848e-01, 1.0746e-01,\n",
      "        1.0645e-01, 1.0544e-01, 1.0445e-01, 1.0346e-01, 1.0247e-01, 1.0150e-01,\n",
      "        1.0053e-01, 9.9567e-02, 9.8613e-02, 9.7667e-02, 9.6727e-02, 9.5794e-02,\n",
      "        9.4869e-02, 9.3950e-02, 9.3039e-02, 9.2134e-02, 9.1237e-02, 9.0346e-02,\n",
      "        8.9463e-02, 8.8586e-02, 8.7716e-02, 8.6853e-02, 8.5996e-02, 8.5146e-02,\n",
      "        8.4303e-02, 8.3467e-02, 8.2637e-02, 8.1814e-02, 8.0998e-02, 8.0188e-02,\n",
      "        7.9384e-02, 7.8587e-02, 7.7797e-02, 7.7012e-02, 7.6235e-02, 7.5463e-02,\n",
      "        7.4698e-02, 7.3939e-02, 7.3186e-02, 7.2440e-02, 7.1700e-02, 7.0966e-02,\n",
      "        7.0238e-02, 6.9516e-02, 6.8800e-02, 6.8090e-02, 6.7386e-02, 6.6688e-02,\n",
      "        6.5996e-02, 6.5309e-02, 6.4629e-02, 6.3954e-02, 6.3285e-02, 6.2622e-02,\n",
      "        6.1965e-02, 6.1313e-02, 6.0667e-02, 6.0026e-02, 5.9391e-02, 5.8762e-02,\n",
      "        5.8138e-02, 5.7520e-02, 5.6907e-02, 5.6299e-02, 5.5697e-02, 5.5100e-02,\n",
      "        5.4508e-02, 5.3922e-02, 5.3341e-02, 5.2765e-02, 5.2194e-02, 5.1628e-02,\n",
      "        5.1068e-02, 5.0513e-02, 4.9962e-02, 4.9417e-02, 4.8876e-02, 4.8341e-02,\n",
      "        4.7810e-02, 4.7284e-02, 4.6764e-02, 4.6247e-02, 4.5736e-02, 4.5230e-02,\n",
      "        4.4728e-02, 4.4231e-02, 4.3738e-02, 4.3250e-02, 4.2767e-02, 4.2288e-02,\n",
      "        4.1814e-02, 4.1344e-02, 4.0879e-02, 4.0418e-02, 3.9961e-02, 3.9509e-02,\n",
      "        3.9061e-02, 3.8618e-02, 3.8178e-02, 3.7743e-02, 3.7312e-02, 3.6886e-02,\n",
      "        3.6463e-02, 3.6045e-02, 3.5631e-02, 3.5220e-02, 3.4814e-02, 3.4412e-02,\n",
      "        3.4014e-02, 3.3619e-02, 3.3229e-02, 3.2842e-02, 3.2460e-02, 3.2081e-02,\n",
      "        3.1705e-02, 3.1334e-02, 3.0966e-02, 3.0603e-02, 3.0242e-02, 2.9886e-02,\n",
      "        2.9533e-02, 2.9183e-02, 2.8837e-02, 2.8495e-02, 2.8156e-02, 2.7821e-02,\n",
      "        2.7489e-02, 2.7160e-02, 2.6835e-02, 2.6513e-02, 2.6195e-02, 2.5879e-02,\n",
      "        2.5567e-02, 2.5259e-02, 2.4953e-02, 2.4651e-02, 2.4352e-02, 2.4056e-02,\n",
      "        2.3763e-02, 2.3474e-02, 2.3187e-02, 2.2903e-02, 2.2623e-02, 2.2345e-02,\n",
      "        2.2071e-02, 2.1799e-02, 2.1530e-02, 2.1264e-02, 2.1001e-02, 2.0741e-02,\n",
      "        2.0484e-02, 2.0229e-02, 1.9977e-02, 1.9728e-02, 1.9482e-02, 1.9238e-02,\n",
      "        1.8997e-02, 1.8758e-02, 1.8523e-02, 1.8289e-02, 1.8059e-02, 1.7831e-02,\n",
      "        1.7605e-02, 1.7382e-02, 1.7161e-02, 1.6943e-02, 1.6728e-02, 1.6514e-02,\n",
      "        1.6304e-02, 1.6095e-02, 1.5889e-02, 1.5685e-02, 1.5484e-02, 1.5284e-02,\n",
      "        1.5087e-02, 1.4893e-02, 1.4700e-02, 1.4510e-02, 1.4321e-02, 1.4135e-02,\n",
      "        1.3952e-02, 1.3770e-02, 1.3590e-02, 1.3413e-02, 1.3237e-02, 1.3064e-02,\n",
      "        1.2892e-02, 1.2723e-02, 1.2555e-02, 1.2389e-02, 1.2226e-02, 1.2064e-02,\n",
      "        1.1904e-02, 1.1746e-02, 1.1590e-02, 1.1436e-02, 1.1284e-02, 1.1133e-02,\n",
      "        1.0984e-02, 1.0837e-02, 1.0692e-02, 1.0548e-02, 1.0407e-02, 1.0266e-02,\n",
      "        1.0128e-02, 9.9911e-03, 9.8560e-03, 9.7225e-03, 9.5906e-03, 9.4603e-03,\n",
      "        9.3316e-03, 9.2044e-03, 9.0788e-03, 8.9548e-03, 8.8322e-03, 8.7112e-03,\n",
      "        8.5916e-03, 8.4735e-03, 8.3569e-03, 8.2417e-03, 8.1279e-03, 8.0155e-03,\n",
      "        7.9046e-03, 7.7950e-03, 7.6867e-03, 7.5799e-03, 7.4743e-03, 7.3701e-03,\n",
      "        7.2672e-03, 7.1655e-03, 7.0652e-03, 6.9661e-03, 6.8683e-03, 6.7717e-03,\n",
      "        6.6763e-03, 6.5822e-03, 6.4892e-03, 6.3974e-03, 6.3068e-03, 6.2173e-03,\n",
      "        6.1290e-03, 6.0419e-03, 5.9558e-03, 5.8709e-03, 5.7870e-03, 5.7042e-03,\n",
      "        5.6225e-03, 5.5419e-03, 5.4623e-03, 5.3837e-03, 5.3062e-03, 5.2297e-03,\n",
      "        5.1541e-03, 5.0796e-03, 5.0060e-03, 4.9334e-03, 4.8618e-03, 4.7911e-03,\n",
      "        4.7213e-03, 4.6525e-03, 4.5845e-03, 4.5175e-03, 4.4514e-03, 4.3861e-03,\n",
      "        4.3217e-03, 4.2582e-03, 4.1955e-03, 4.1336e-03, 4.0726e-03, 4.0124e-03,\n",
      "        3.9530e-03, 3.8945e-03, 3.8367e-03, 3.7796e-03, 3.7234e-03, 3.6679e-03,\n",
      "        3.6132e-03, 3.5592e-03, 3.5060e-03, 3.4534e-03, 3.4016e-03, 3.3506e-03,\n",
      "        3.3002e-03, 3.2505e-03, 3.2014e-03, 3.1531e-03, 3.1054e-03, 3.0584e-03,\n",
      "        3.0120e-03, 2.9663e-03, 2.9212e-03, 2.8768e-03, 2.8329e-03, 2.7897e-03,\n",
      "        2.7471e-03, 2.7051e-03, 2.6636e-03, 2.6228e-03, 2.5825e-03, 2.5428e-03,\n",
      "        2.5036e-03, 2.4650e-03, 2.4270e-03, 2.3894e-03, 2.3525e-03, 2.3160e-03,\n",
      "        2.2801e-03, 2.2446e-03, 2.2097e-03, 2.1753e-03, 2.1414e-03, 2.1079e-03,\n",
      "        2.0750e-03, 2.0425e-03, 2.0104e-03, 1.9789e-03, 1.9478e-03, 1.9171e-03,\n",
      "        1.8869e-03, 1.8572e-03, 1.8278e-03, 1.7989e-03, 1.7704e-03, 1.7423e-03,\n",
      "        1.7147e-03, 1.6874e-03, 1.6606e-03, 1.6341e-03, 1.6080e-03, 1.5823e-03,\n",
      "        1.5570e-03, 1.5321e-03, 1.5075e-03, 1.4833e-03, 1.4595e-03, 1.4360e-03,\n",
      "        1.4128e-03, 1.3900e-03, 1.3676e-03, 1.3455e-03, 1.3237e-03, 1.3022e-03,\n",
      "        1.2811e-03, 1.2602e-03, 1.2397e-03, 1.2195e-03, 1.1996e-03, 1.1800e-03,\n",
      "        1.1607e-03, 1.1417e-03, 1.1230e-03, 1.1046e-03, 1.0864e-03, 1.0686e-03,\n",
      "        1.0509e-03, 1.0336e-03, 1.0165e-03, 9.9974e-04, 9.8319e-04, 9.6689e-04,\n",
      "        9.5085e-04, 9.3505e-04, 9.1950e-04, 9.0419e-04, 8.8911e-04, 8.7427e-04,\n",
      "        8.5966e-04, 8.4527e-04, 8.3111e-04, 8.1717e-04, 8.0345e-04, 7.8994e-04,\n",
      "        7.7664e-04, 7.6355e-04, 7.5067e-04, 7.3799e-04, 7.2551e-04, 7.1322e-04,\n",
      "        7.0113e-04, 6.8923e-04, 6.7752e-04, 6.6600e-04, 6.5465e-04, 6.4349e-04,\n",
      "        6.3250e-04, 6.2169e-04, 6.1106e-04, 6.0059e-04, 5.9029e-04, 5.8015e-04,\n",
      "        5.7018e-04, 5.6036e-04, 5.5071e-04, 5.4121e-04, 5.3186e-04, 5.2266e-04,\n",
      "        5.1362e-04, 5.0472e-04, 4.9596e-04, 4.8734e-04, 4.7887e-04, 4.7053e-04,\n",
      "        4.6233e-04, 4.5426e-04, 4.4633e-04, 4.3852e-04, 4.3084e-04, 4.2329e-04,\n",
      "        4.1586e-04, 4.0855e-04, 4.0137e-04, 3.9430e-04, 3.8735e-04, 3.8051e-04,\n",
      "        3.7379e-04, 3.6718e-04, 3.6067e-04, 3.5428e-04, 3.4799e-04, 3.4181e-04,\n",
      "        3.3573e-04, 3.2975e-04, 3.2387e-04, 3.1809e-04, 3.1240e-04, 3.0682e-04,\n",
      "        3.0132e-04, 2.9592e-04, 2.9061e-04, 2.8539e-04, 2.8025e-04, 2.7521e-04,\n",
      "        2.7024e-04, 2.6537e-04, 2.6057e-04, 2.5586e-04, 2.5123e-04, 2.4667e-04,\n",
      "        2.4220e-04, 2.3780e-04, 2.3347e-04, 2.2922e-04, 2.2504e-04, 2.2094e-04,\n",
      "        2.1690e-04, 2.1293e-04, 2.0904e-04, 2.0520e-04, 2.0144e-04, 1.9774e-04,\n",
      "        1.9410e-04, 1.9053e-04, 1.8702e-04, 1.8357e-04, 1.8018e-04, 1.7685e-04,\n",
      "        1.7358e-04, 1.7036e-04, 1.6720e-04, 1.6410e-04, 1.6105e-04, 1.5805e-04,\n",
      "        1.5511e-04, 1.5222e-04, 1.4937e-04, 1.4658e-04, 1.4384e-04, 1.4115e-04,\n",
      "        1.3850e-04, 1.3590e-04, 1.3335e-04, 1.3084e-04, 1.2838e-04, 1.2596e-04,\n",
      "        1.2358e-04, 1.2125e-04, 1.1896e-04, 1.1671e-04, 1.1450e-04, 1.1232e-04,\n",
      "        1.1019e-04, 1.0810e-04, 1.0604e-04, 1.0402e-04, 1.0204e-04, 1.0009e-04,\n",
      "        9.8180e-05, 9.6302e-05, 9.4459e-05, 9.2649e-05, 9.0871e-05, 8.9126e-05,\n",
      "        8.7413e-05, 8.5731e-05, 8.4080e-05, 8.2458e-05, 8.0867e-05, 7.9304e-05,\n",
      "        7.7770e-05, 7.6264e-05, 7.4786e-05, 7.3335e-05, 7.1911e-05, 7.0513e-05,\n",
      "        6.9140e-05, 6.7793e-05, 6.6471e-05, 6.5173e-05, 6.3900e-05, 6.2650e-05,\n",
      "        6.1423e-05, 6.0219e-05, 5.9038e-05, 5.7878e-05, 5.6740e-05, 5.5623e-05,\n",
      "        5.4527e-05, 5.3452e-05, 5.2397e-05, 5.1361e-05, 5.0345e-05, 4.9349e-05,\n",
      "        4.8370e-05, 4.7411e-05, 4.6469e-05, 4.5545e-05, 4.4639e-05, 4.3750e-05,\n",
      "        4.2877e-05, 4.2022e-05, 4.1182e-05, 4.0358e-05], dtype=torch.float64)\n",
      "betas:\n",
      "\ttensor([0.0001, 0.0001, 0.0001, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0003,\n",
      "        0.0003, 0.0003, 0.0003, 0.0003, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004,\n",
      "        0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0006, 0.0006, 0.0006, 0.0006,\n",
      "        0.0006, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0008, 0.0008, 0.0008,\n",
      "        0.0008, 0.0008, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0010, 0.0010,\n",
      "        0.0010, 0.0010, 0.0010, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0012,\n",
      "        0.0012, 0.0012, 0.0012, 0.0012, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013,\n",
      "        0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0015, 0.0015, 0.0015, 0.0015,\n",
      "        0.0015, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0017, 0.0017, 0.0017,\n",
      "        0.0017, 0.0017, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0019, 0.0019,\n",
      "        0.0019, 0.0019, 0.0019, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0021,\n",
      "        0.0021, 0.0021, 0.0021, 0.0021, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022,\n",
      "        0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0024, 0.0024, 0.0024, 0.0024,\n",
      "        0.0024, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0026, 0.0026, 0.0026,\n",
      "        0.0026, 0.0026, 0.0026, 0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0028,\n",
      "        0.0028, 0.0028, 0.0028, 0.0028, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029,\n",
      "        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0031, 0.0031, 0.0031, 0.0031,\n",
      "        0.0031, 0.0032, 0.0032, 0.0032, 0.0032, 0.0032, 0.0033, 0.0033, 0.0033,\n",
      "        0.0033, 0.0033, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0035, 0.0035,\n",
      "        0.0035, 0.0035, 0.0035, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0037,\n",
      "        0.0037, 0.0037, 0.0037, 0.0037, 0.0038, 0.0038, 0.0038, 0.0038, 0.0038,\n",
      "        0.0039, 0.0039, 0.0039, 0.0039, 0.0039, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "        0.0040, 0.0041, 0.0041, 0.0041, 0.0041, 0.0041, 0.0042, 0.0042, 0.0042,\n",
      "        0.0042, 0.0042, 0.0043, 0.0043, 0.0043, 0.0043, 0.0043, 0.0044, 0.0044,\n",
      "        0.0044, 0.0044, 0.0044, 0.0045, 0.0045, 0.0045, 0.0045, 0.0045, 0.0046,\n",
      "        0.0046, 0.0046, 0.0046, 0.0046, 0.0047, 0.0047, 0.0047, 0.0047, 0.0047,\n",
      "        0.0048, 0.0048, 0.0048, 0.0048, 0.0048, 0.0049, 0.0049, 0.0049, 0.0049,\n",
      "        0.0049, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0051, 0.0051, 0.0051,\n",
      "        0.0051, 0.0051, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0053, 0.0053,\n",
      "        0.0053, 0.0053, 0.0053, 0.0054, 0.0054, 0.0054, 0.0054, 0.0054, 0.0055,\n",
      "        0.0055, 0.0055, 0.0055, 0.0055, 0.0056, 0.0056, 0.0056, 0.0056, 0.0056,\n",
      "        0.0057, 0.0057, 0.0057, 0.0057, 0.0057, 0.0058, 0.0058, 0.0058, 0.0058,\n",
      "        0.0058, 0.0059, 0.0059, 0.0059, 0.0059, 0.0059, 0.0060, 0.0060, 0.0060,\n",
      "        0.0060, 0.0060, 0.0061, 0.0061, 0.0061, 0.0061, 0.0061, 0.0062, 0.0062,\n",
      "        0.0062, 0.0062, 0.0062, 0.0063, 0.0063, 0.0063, 0.0063, 0.0063, 0.0064,\n",
      "        0.0064, 0.0064, 0.0064, 0.0064, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065,\n",
      "        0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0067, 0.0067, 0.0067, 0.0067,\n",
      "        0.0067, 0.0068, 0.0068, 0.0068, 0.0068, 0.0068, 0.0069, 0.0069, 0.0069,\n",
      "        0.0069, 0.0069, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0071, 0.0071,\n",
      "        0.0071, 0.0071, 0.0071, 0.0072, 0.0072, 0.0072, 0.0072, 0.0072, 0.0073,\n",
      "        0.0073, 0.0073, 0.0073, 0.0073, 0.0074, 0.0074, 0.0074, 0.0074, 0.0074,\n",
      "        0.0075, 0.0075, 0.0075, 0.0075, 0.0075, 0.0076, 0.0076, 0.0076, 0.0076,\n",
      "        0.0076, 0.0076, 0.0077, 0.0077, 0.0077, 0.0077, 0.0077, 0.0078, 0.0078,\n",
      "        0.0078, 0.0078, 0.0078, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0080,\n",
      "        0.0080, 0.0080, 0.0080, 0.0080, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0082, 0.0082, 0.0082, 0.0082, 0.0082, 0.0083, 0.0083, 0.0083, 0.0083,\n",
      "        0.0083, 0.0084, 0.0084, 0.0084, 0.0084, 0.0084, 0.0085, 0.0085, 0.0085,\n",
      "        0.0085, 0.0085, 0.0086, 0.0086, 0.0086, 0.0086, 0.0086, 0.0087, 0.0087,\n",
      "        0.0087, 0.0087, 0.0087, 0.0088, 0.0088, 0.0088, 0.0088, 0.0088, 0.0089,\n",
      "        0.0089, 0.0089, 0.0089, 0.0089, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0092, 0.0092, 0.0092, 0.0092,\n",
      "        0.0092, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0094, 0.0094, 0.0094,\n",
      "        0.0094, 0.0094, 0.0095, 0.0095, 0.0095, 0.0095, 0.0095, 0.0096, 0.0096,\n",
      "        0.0096, 0.0096, 0.0096, 0.0097, 0.0097, 0.0097, 0.0097, 0.0097, 0.0098,\n",
      "        0.0098, 0.0098, 0.0098, 0.0098, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0101, 0.0101, 0.0101, 0.0101,\n",
      "        0.0101, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0103, 0.0103, 0.0103,\n",
      "        0.0103, 0.0103, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0105, 0.0105,\n",
      "        0.0105, 0.0105, 0.0105, 0.0106, 0.0106, 0.0106, 0.0106, 0.0106, 0.0107,\n",
      "        0.0107, 0.0107, 0.0107, 0.0107, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108,\n",
      "        0.0109, 0.0109, 0.0109, 0.0109, 0.0109, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "        0.0110, 0.0111, 0.0111, 0.0111, 0.0111, 0.0111, 0.0112, 0.0112, 0.0112,\n",
      "        0.0112, 0.0112, 0.0113, 0.0113, 0.0113, 0.0113, 0.0113, 0.0114, 0.0114,\n",
      "        0.0114, 0.0114, 0.0114, 0.0115, 0.0115, 0.0115, 0.0115, 0.0115, 0.0116,\n",
      "        0.0116, 0.0116, 0.0116, 0.0116, 0.0117, 0.0117, 0.0117, 0.0117, 0.0117,\n",
      "        0.0118, 0.0118, 0.0118, 0.0118, 0.0118, 0.0119, 0.0119, 0.0119, 0.0119,\n",
      "        0.0119, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0121, 0.0121, 0.0121,\n",
      "        0.0121, 0.0121, 0.0122, 0.0122, 0.0122, 0.0122, 0.0122, 0.0123, 0.0123,\n",
      "        0.0123, 0.0123, 0.0123, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0125,\n",
      "        0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0126, 0.0126, 0.0126, 0.0126,\n",
      "        0.0126, 0.0127, 0.0127, 0.0127, 0.0127, 0.0127, 0.0128, 0.0128, 0.0128,\n",
      "        0.0128, 0.0128, 0.0129, 0.0129, 0.0129, 0.0129, 0.0129, 0.0130, 0.0130,\n",
      "        0.0130, 0.0130, 0.0130, 0.0131, 0.0131, 0.0131, 0.0131, 0.0131, 0.0132,\n",
      "        0.0132, 0.0132, 0.0132, 0.0132, 0.0133, 0.0133, 0.0133, 0.0133, 0.0133,\n",
      "        0.0134, 0.0134, 0.0134, 0.0134, 0.0134, 0.0135, 0.0135, 0.0135, 0.0135,\n",
      "        0.0135, 0.0136, 0.0136, 0.0136, 0.0136, 0.0136, 0.0137, 0.0137, 0.0137,\n",
      "        0.0137, 0.0137, 0.0138, 0.0138, 0.0138, 0.0138, 0.0138, 0.0139, 0.0139,\n",
      "        0.0139, 0.0139, 0.0139, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0141,\n",
      "        0.0141, 0.0141, 0.0141, 0.0141, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
      "        0.0143, 0.0143, 0.0143, 0.0143, 0.0143, 0.0144, 0.0144, 0.0144, 0.0144,\n",
      "        0.0144, 0.0145, 0.0145, 0.0145, 0.0145, 0.0145, 0.0146, 0.0146, 0.0146,\n",
      "        0.0146, 0.0146, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0148, 0.0148,\n",
      "        0.0148, 0.0148, 0.0148, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0150,\n",
      "        0.0150, 0.0150, 0.0150, 0.0150, 0.0151, 0.0151, 0.0151, 0.0151, 0.0151,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0153, 0.0153, 0.0153, 0.0153,\n",
      "        0.0153, 0.0154, 0.0154, 0.0154, 0.0154, 0.0154, 0.0155, 0.0155, 0.0155,\n",
      "        0.0155, 0.0155, 0.0156, 0.0156, 0.0156, 0.0156, 0.0156, 0.0157, 0.0157,\n",
      "        0.0157, 0.0157, 0.0157, 0.0158, 0.0158, 0.0158, 0.0158, 0.0158, 0.0159,\n",
      "        0.0159, 0.0159, 0.0159, 0.0159, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "        0.0161, 0.0161, 0.0161, 0.0161, 0.0161, 0.0162, 0.0162, 0.0162, 0.0162,\n",
      "        0.0162, 0.0163, 0.0163, 0.0163, 0.0163, 0.0163, 0.0164, 0.0164, 0.0164,\n",
      "        0.0164, 0.0164, 0.0165, 0.0165, 0.0165, 0.0165, 0.0165, 0.0166, 0.0166,\n",
      "        0.0166, 0.0166, 0.0166, 0.0167, 0.0167, 0.0167, 0.0167, 0.0167, 0.0168,\n",
      "        0.0168, 0.0168, 0.0168, 0.0168, 0.0169, 0.0169, 0.0169, 0.0169, 0.0169,\n",
      "        0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0171, 0.0171, 0.0171, 0.0171,\n",
      "        0.0171, 0.0172, 0.0172, 0.0172, 0.0172, 0.0172, 0.0173, 0.0173, 0.0173,\n",
      "        0.0173, 0.0173, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0175, 0.0175,\n",
      "        0.0175, 0.0175, 0.0175, 0.0175, 0.0176, 0.0176, 0.0176, 0.0176, 0.0176,\n",
      "        0.0177, 0.0177, 0.0177, 0.0177, 0.0177, 0.0178, 0.0178, 0.0178, 0.0178,\n",
      "        0.0178, 0.0179, 0.0179, 0.0179, 0.0179, 0.0179, 0.0180, 0.0180, 0.0180,\n",
      "        0.0180, 0.0180, 0.0181, 0.0181, 0.0181, 0.0181, 0.0181, 0.0182, 0.0182,\n",
      "        0.0182, 0.0182, 0.0182, 0.0183, 0.0183, 0.0183, 0.0183, 0.0183, 0.0184,\n",
      "        0.0184, 0.0184, 0.0184, 0.0184, 0.0185, 0.0185, 0.0185, 0.0185, 0.0185,\n",
      "        0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0187, 0.0187, 0.0187, 0.0187,\n",
      "        0.0187, 0.0188, 0.0188, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189,\n",
      "        0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0191, 0.0191,\n",
      "        0.0191, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0192, 0.0192, 0.0193,\n",
      "        0.0193, 0.0193, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194,\n",
      "        0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "        0.0196, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0198, 0.0198, 0.0198,\n",
      "        0.0198, 0.0198, 0.0199, 0.0199, 0.0199, 0.0199, 0.0199, 0.0200, 0.0200,\n",
      "        0.0200], dtype=torch.float64)\n",
      "alphas_cumprod:\n",
      "\ttensor([9.9990e-01, 9.9978e-01, 9.9964e-01, 9.9948e-01, 9.9930e-01, 9.9910e-01,\n",
      "        9.9888e-01, 9.9864e-01, 9.9838e-01, 9.9811e-01, 9.9781e-01, 9.9749e-01,\n",
      "        9.9715e-01, 9.9679e-01, 9.9641e-01, 9.9602e-01, 9.9560e-01, 9.9516e-01,\n",
      "        9.9471e-01, 9.9423e-01, 9.9374e-01, 9.9322e-01, 9.9269e-01, 9.9213e-01,\n",
      "        9.9156e-01, 9.9097e-01, 9.9035e-01, 9.8972e-01, 9.8907e-01, 9.8840e-01,\n",
      "        9.8771e-01, 9.8700e-01, 9.8627e-01, 9.8553e-01, 9.8476e-01, 9.8398e-01,\n",
      "        9.8317e-01, 9.8235e-01, 9.8151e-01, 9.8065e-01, 9.7977e-01, 9.7887e-01,\n",
      "        9.7795e-01, 9.7702e-01, 9.7606e-01, 9.7509e-01, 9.7410e-01, 9.7309e-01,\n",
      "        9.7206e-01, 9.7102e-01, 9.6995e-01, 9.6887e-01, 9.6777e-01, 9.6665e-01,\n",
      "        9.6551e-01, 9.6436e-01, 9.6319e-01, 9.6200e-01, 9.6079e-01, 9.5956e-01,\n",
      "        9.5832e-01, 9.5706e-01, 9.5578e-01, 9.5449e-01, 9.5318e-01, 9.5185e-01,\n",
      "        9.5050e-01, 9.4914e-01, 9.4776e-01, 9.4636e-01, 9.4494e-01, 9.4351e-01,\n",
      "        9.4207e-01, 9.4060e-01, 9.3912e-01, 9.3762e-01, 9.3611e-01, 9.3458e-01,\n",
      "        9.3304e-01, 9.3147e-01, 9.2990e-01, 9.2830e-01, 9.2669e-01, 9.2507e-01,\n",
      "        9.2343e-01, 9.2177e-01, 9.2010e-01, 9.1842e-01, 9.1671e-01, 9.1500e-01,\n",
      "        9.1326e-01, 9.1152e-01, 9.0976e-01, 9.0798e-01, 9.0619e-01, 9.0438e-01,\n",
      "        9.0256e-01, 9.0073e-01, 8.9888e-01, 8.9702e-01, 8.9514e-01, 8.9325e-01,\n",
      "        8.9135e-01, 8.8943e-01, 8.8750e-01, 8.8555e-01, 8.8359e-01, 8.8162e-01,\n",
      "        8.7964e-01, 8.7764e-01, 8.7563e-01, 8.7360e-01, 8.7157e-01, 8.6952e-01,\n",
      "        8.6746e-01, 8.6538e-01, 8.6330e-01, 8.6120e-01, 8.5909e-01, 8.5697e-01,\n",
      "        8.5483e-01, 8.5269e-01, 8.5053e-01, 8.4836e-01, 8.4618e-01, 8.4399e-01,\n",
      "        8.4179e-01, 8.3957e-01, 8.3735e-01, 8.3511e-01, 8.3287e-01, 8.3061e-01,\n",
      "        8.2834e-01, 8.2606e-01, 8.2378e-01, 8.2148e-01, 8.1917e-01, 8.1685e-01,\n",
      "        8.1453e-01, 8.1219e-01, 8.0984e-01, 8.0749e-01, 8.0512e-01, 8.0275e-01,\n",
      "        8.0037e-01, 7.9797e-01, 7.9557e-01, 7.9317e-01, 7.9075e-01, 7.8832e-01,\n",
      "        7.8589e-01, 7.8344e-01, 7.8099e-01, 7.7854e-01, 7.7607e-01, 7.7360e-01,\n",
      "        7.7111e-01, 7.6863e-01, 7.6613e-01, 7.6363e-01, 7.6112e-01, 7.5860e-01,\n",
      "        7.5608e-01, 7.5354e-01, 7.5101e-01, 7.4846e-01, 7.4591e-01, 7.4336e-01,\n",
      "        7.4080e-01, 7.3823e-01, 7.3565e-01, 7.3308e-01, 7.3049e-01, 7.2790e-01,\n",
      "        7.2530e-01, 7.2270e-01, 7.2010e-01, 7.1749e-01, 7.1487e-01, 7.1225e-01,\n",
      "        7.0963e-01, 7.0700e-01, 7.0436e-01, 7.0172e-01, 6.9908e-01, 6.9644e-01,\n",
      "        6.9379e-01, 6.9113e-01, 6.8847e-01, 6.8581e-01, 6.8315e-01, 6.8048e-01,\n",
      "        6.7781e-01, 6.7514e-01, 6.7246e-01, 6.6978e-01, 6.6710e-01, 6.6441e-01,\n",
      "        6.6173e-01, 6.5904e-01, 6.5635e-01, 6.5365e-01, 6.5096e-01, 6.4826e-01,\n",
      "        6.4556e-01, 6.4286e-01, 6.4016e-01, 6.3745e-01, 6.3475e-01, 6.3204e-01,\n",
      "        6.2934e-01, 6.2663e-01, 6.2392e-01, 6.2121e-01, 6.1850e-01, 6.1579e-01,\n",
      "        6.1308e-01, 6.1037e-01, 6.0765e-01, 6.0494e-01, 6.0223e-01, 5.9952e-01,\n",
      "        5.9681e-01, 5.9410e-01, 5.9139e-01, 5.8868e-01, 5.8597e-01, 5.8326e-01,\n",
      "        5.8055e-01, 5.7785e-01, 5.7514e-01, 5.7244e-01, 5.6974e-01, 5.6703e-01,\n",
      "        5.6433e-01, 5.6164e-01, 5.5894e-01, 5.5624e-01, 5.5355e-01, 5.5086e-01,\n",
      "        5.4817e-01, 5.4549e-01, 5.4280e-01, 5.4012e-01, 5.3744e-01, 5.3476e-01,\n",
      "        5.3209e-01, 5.2942e-01, 5.2675e-01, 5.2409e-01, 5.2142e-01, 5.1876e-01,\n",
      "        5.1611e-01, 5.1346e-01, 5.1081e-01, 5.0816e-01, 5.0552e-01, 5.0288e-01,\n",
      "        5.0024e-01, 4.9761e-01, 4.9499e-01, 4.9236e-01, 4.8974e-01, 4.8713e-01,\n",
      "        4.8452e-01, 4.8191e-01, 4.7931e-01, 4.7671e-01, 4.7412e-01, 4.7153e-01,\n",
      "        4.6895e-01, 4.6637e-01, 4.6380e-01, 4.6123e-01, 4.5867e-01, 4.5611e-01,\n",
      "        4.5356e-01, 4.5101e-01, 4.4846e-01, 4.4593e-01, 4.4340e-01, 4.4087e-01,\n",
      "        4.3835e-01, 4.3583e-01, 4.3332e-01, 4.3082e-01, 4.2832e-01, 4.2583e-01,\n",
      "        4.2335e-01, 4.2087e-01, 4.1839e-01, 4.1593e-01, 4.1347e-01, 4.1101e-01,\n",
      "        4.0856e-01, 4.0612e-01, 4.0369e-01, 4.0126e-01, 3.9884e-01, 3.9642e-01,\n",
      "        3.9401e-01, 3.9161e-01, 3.8921e-01, 3.8683e-01, 3.8444e-01, 3.8207e-01,\n",
      "        3.7970e-01, 3.7734e-01, 3.7499e-01, 3.7265e-01, 3.7031e-01, 3.6798e-01,\n",
      "        3.6565e-01, 3.6334e-01, 3.6103e-01, 3.5873e-01, 3.5643e-01, 3.5414e-01,\n",
      "        3.5187e-01, 3.4959e-01, 3.4733e-01, 3.4508e-01, 3.4283e-01, 3.4059e-01,\n",
      "        3.3836e-01, 3.3613e-01, 3.3391e-01, 3.3171e-01, 3.2951e-01, 3.2731e-01,\n",
      "        3.2513e-01, 3.2295e-01, 3.2078e-01, 3.1862e-01, 3.1647e-01, 3.1433e-01,\n",
      "        3.1219e-01, 3.1007e-01, 3.0795e-01, 3.0584e-01, 3.0374e-01, 3.0164e-01,\n",
      "        2.9956e-01, 2.9748e-01, 2.9541e-01, 2.9335e-01, 2.9130e-01, 2.8926e-01,\n",
      "        2.8723e-01, 2.8520e-01, 2.8318e-01, 2.8117e-01, 2.7917e-01, 2.7718e-01,\n",
      "        2.7520e-01, 2.7323e-01, 2.7126e-01, 2.6931e-01, 2.6736e-01, 2.6542e-01,\n",
      "        2.6349e-01, 2.6157e-01, 2.5966e-01, 2.5775e-01, 2.5586e-01, 2.5397e-01,\n",
      "        2.5210e-01, 2.5023e-01, 2.4837e-01, 2.4652e-01, 2.4468e-01, 2.4284e-01,\n",
      "        2.4102e-01, 2.3920e-01, 2.3740e-01, 2.3560e-01, 2.3381e-01, 2.3203e-01,\n",
      "        2.3026e-01, 2.2850e-01, 2.2675e-01, 2.2501e-01, 2.2327e-01, 2.2155e-01,\n",
      "        2.1983e-01, 2.1812e-01, 2.1642e-01, 2.1473e-01, 2.1305e-01, 2.1138e-01,\n",
      "        2.0972e-01, 2.0806e-01, 2.0642e-01, 2.0478e-01, 2.0315e-01, 2.0153e-01,\n",
      "        1.9992e-01, 1.9832e-01, 1.9673e-01, 1.9515e-01, 1.9357e-01, 1.9201e-01,\n",
      "        1.9045e-01, 1.8890e-01, 1.8736e-01, 1.8583e-01, 1.8431e-01, 1.8280e-01,\n",
      "        1.8129e-01, 1.7980e-01, 1.7831e-01, 1.7683e-01, 1.7537e-01, 1.7391e-01,\n",
      "        1.7245e-01, 1.7101e-01, 1.6958e-01, 1.6815e-01, 1.6673e-01, 1.6533e-01,\n",
      "        1.6393e-01, 1.6254e-01, 1.6115e-01, 1.5978e-01, 1.5841e-01, 1.5706e-01,\n",
      "        1.5571e-01, 1.5437e-01, 1.5304e-01, 1.5171e-01, 1.5040e-01, 1.4909e-01,\n",
      "        1.4779e-01, 1.4650e-01, 1.4522e-01, 1.4395e-01, 1.4269e-01, 1.4143e-01,\n",
      "        1.4018e-01, 1.3894e-01, 1.3771e-01, 1.3649e-01, 1.3527e-01, 1.3406e-01,\n",
      "        1.3286e-01, 1.3167e-01, 1.3049e-01, 1.2932e-01, 1.2815e-01, 1.2699e-01,\n",
      "        1.2584e-01, 1.2470e-01, 1.2356e-01, 1.2243e-01, 1.2131e-01, 1.2020e-01,\n",
      "        1.1910e-01, 1.1800e-01, 1.1691e-01, 1.1583e-01, 1.1476e-01, 1.1369e-01,\n",
      "        1.1264e-01, 1.1159e-01, 1.1054e-01, 1.0951e-01, 1.0848e-01, 1.0746e-01,\n",
      "        1.0645e-01, 1.0544e-01, 1.0445e-01, 1.0346e-01, 1.0247e-01, 1.0150e-01,\n",
      "        1.0053e-01, 9.9567e-02, 9.8613e-02, 9.7667e-02, 9.6727e-02, 9.5794e-02,\n",
      "        9.4869e-02, 9.3950e-02, 9.3039e-02, 9.2134e-02, 9.1237e-02, 9.0346e-02,\n",
      "        8.9463e-02, 8.8586e-02, 8.7716e-02, 8.6853e-02, 8.5996e-02, 8.5146e-02,\n",
      "        8.4303e-02, 8.3467e-02, 8.2637e-02, 8.1814e-02, 8.0998e-02, 8.0188e-02,\n",
      "        7.9384e-02, 7.8587e-02, 7.7797e-02, 7.7012e-02, 7.6235e-02, 7.5463e-02,\n",
      "        7.4698e-02, 7.3939e-02, 7.3186e-02, 7.2440e-02, 7.1700e-02, 7.0966e-02,\n",
      "        7.0238e-02, 6.9516e-02, 6.8800e-02, 6.8090e-02, 6.7386e-02, 6.6688e-02,\n",
      "        6.5996e-02, 6.5309e-02, 6.4629e-02, 6.3954e-02, 6.3285e-02, 6.2622e-02,\n",
      "        6.1965e-02, 6.1313e-02, 6.0667e-02, 6.0026e-02, 5.9391e-02, 5.8762e-02,\n",
      "        5.8138e-02, 5.7520e-02, 5.6907e-02, 5.6299e-02, 5.5697e-02, 5.5100e-02,\n",
      "        5.4508e-02, 5.3922e-02, 5.3341e-02, 5.2765e-02, 5.2194e-02, 5.1628e-02,\n",
      "        5.1068e-02, 5.0513e-02, 4.9962e-02, 4.9417e-02, 4.8876e-02, 4.8341e-02,\n",
      "        4.7810e-02, 4.7284e-02, 4.6764e-02, 4.6247e-02, 4.5736e-02, 4.5230e-02,\n",
      "        4.4728e-02, 4.4231e-02, 4.3738e-02, 4.3250e-02, 4.2767e-02, 4.2288e-02,\n",
      "        4.1814e-02, 4.1344e-02, 4.0879e-02, 4.0418e-02, 3.9961e-02, 3.9509e-02,\n",
      "        3.9061e-02, 3.8618e-02, 3.8178e-02, 3.7743e-02, 3.7312e-02, 3.6886e-02,\n",
      "        3.6463e-02, 3.6045e-02, 3.5631e-02, 3.5220e-02, 3.4814e-02, 3.4412e-02,\n",
      "        3.4014e-02, 3.3619e-02, 3.3229e-02, 3.2842e-02, 3.2460e-02, 3.2081e-02,\n",
      "        3.1705e-02, 3.1334e-02, 3.0966e-02, 3.0603e-02, 3.0242e-02, 2.9886e-02,\n",
      "        2.9533e-02, 2.9183e-02, 2.8837e-02, 2.8495e-02, 2.8156e-02, 2.7821e-02,\n",
      "        2.7489e-02, 2.7160e-02, 2.6835e-02, 2.6513e-02, 2.6195e-02, 2.5879e-02,\n",
      "        2.5567e-02, 2.5259e-02, 2.4953e-02, 2.4651e-02, 2.4352e-02, 2.4056e-02,\n",
      "        2.3763e-02, 2.3474e-02, 2.3187e-02, 2.2903e-02, 2.2623e-02, 2.2345e-02,\n",
      "        2.2071e-02, 2.1799e-02, 2.1530e-02, 2.1264e-02, 2.1001e-02, 2.0741e-02,\n",
      "        2.0484e-02, 2.0229e-02, 1.9977e-02, 1.9728e-02, 1.9482e-02, 1.9238e-02,\n",
      "        1.8997e-02, 1.8758e-02, 1.8523e-02, 1.8289e-02, 1.8059e-02, 1.7831e-02,\n",
      "        1.7605e-02, 1.7382e-02, 1.7161e-02, 1.6943e-02, 1.6728e-02, 1.6514e-02,\n",
      "        1.6304e-02, 1.6095e-02, 1.5889e-02, 1.5685e-02, 1.5484e-02, 1.5284e-02,\n",
      "        1.5087e-02, 1.4893e-02, 1.4700e-02, 1.4510e-02, 1.4321e-02, 1.4135e-02,\n",
      "        1.3952e-02, 1.3770e-02, 1.3590e-02, 1.3413e-02, 1.3237e-02, 1.3064e-02,\n",
      "        1.2892e-02, 1.2723e-02, 1.2555e-02, 1.2389e-02, 1.2226e-02, 1.2064e-02,\n",
      "        1.1904e-02, 1.1746e-02, 1.1590e-02, 1.1436e-02, 1.1284e-02, 1.1133e-02,\n",
      "        1.0984e-02, 1.0837e-02, 1.0692e-02, 1.0548e-02, 1.0407e-02, 1.0266e-02,\n",
      "        1.0128e-02, 9.9911e-03, 9.8560e-03, 9.7225e-03, 9.5906e-03, 9.4603e-03,\n",
      "        9.3316e-03, 9.2044e-03, 9.0788e-03, 8.9548e-03, 8.8322e-03, 8.7112e-03,\n",
      "        8.5916e-03, 8.4735e-03, 8.3569e-03, 8.2417e-03, 8.1279e-03, 8.0155e-03,\n",
      "        7.9046e-03, 7.7950e-03, 7.6867e-03, 7.5799e-03, 7.4743e-03, 7.3701e-03,\n",
      "        7.2672e-03, 7.1655e-03, 7.0652e-03, 6.9661e-03, 6.8683e-03, 6.7717e-03,\n",
      "        6.6763e-03, 6.5822e-03, 6.4892e-03, 6.3974e-03, 6.3068e-03, 6.2173e-03,\n",
      "        6.1290e-03, 6.0419e-03, 5.9558e-03, 5.8709e-03, 5.7870e-03, 5.7042e-03,\n",
      "        5.6225e-03, 5.5419e-03, 5.4623e-03, 5.3837e-03, 5.3062e-03, 5.2297e-03,\n",
      "        5.1541e-03, 5.0796e-03, 5.0060e-03, 4.9334e-03, 4.8618e-03, 4.7911e-03,\n",
      "        4.7213e-03, 4.6525e-03, 4.5845e-03, 4.5175e-03, 4.4514e-03, 4.3861e-03,\n",
      "        4.3217e-03, 4.2582e-03, 4.1955e-03, 4.1336e-03, 4.0726e-03, 4.0124e-03,\n",
      "        3.9530e-03, 3.8945e-03, 3.8367e-03, 3.7796e-03, 3.7234e-03, 3.6679e-03,\n",
      "        3.6132e-03, 3.5592e-03, 3.5060e-03, 3.4534e-03, 3.4016e-03, 3.3506e-03,\n",
      "        3.3002e-03, 3.2505e-03, 3.2014e-03, 3.1531e-03, 3.1054e-03, 3.0584e-03,\n",
      "        3.0120e-03, 2.9663e-03, 2.9212e-03, 2.8768e-03, 2.8329e-03, 2.7897e-03,\n",
      "        2.7471e-03, 2.7051e-03, 2.6636e-03, 2.6228e-03, 2.5825e-03, 2.5428e-03,\n",
      "        2.5036e-03, 2.4650e-03, 2.4270e-03, 2.3894e-03, 2.3525e-03, 2.3160e-03,\n",
      "        2.2801e-03, 2.2446e-03, 2.2097e-03, 2.1753e-03, 2.1414e-03, 2.1079e-03,\n",
      "        2.0750e-03, 2.0425e-03, 2.0104e-03, 1.9789e-03, 1.9478e-03, 1.9171e-03,\n",
      "        1.8869e-03, 1.8572e-03, 1.8278e-03, 1.7989e-03, 1.7704e-03, 1.7423e-03,\n",
      "        1.7147e-03, 1.6874e-03, 1.6606e-03, 1.6341e-03, 1.6080e-03, 1.5823e-03,\n",
      "        1.5570e-03, 1.5321e-03, 1.5075e-03, 1.4833e-03, 1.4595e-03, 1.4360e-03,\n",
      "        1.4128e-03, 1.3900e-03, 1.3676e-03, 1.3455e-03, 1.3237e-03, 1.3022e-03,\n",
      "        1.2811e-03, 1.2602e-03, 1.2397e-03, 1.2195e-03, 1.1996e-03, 1.1800e-03,\n",
      "        1.1607e-03, 1.1417e-03, 1.1230e-03, 1.1046e-03, 1.0864e-03, 1.0686e-03,\n",
      "        1.0509e-03, 1.0336e-03, 1.0165e-03, 9.9974e-04, 9.8319e-04, 9.6689e-04,\n",
      "        9.5085e-04, 9.3505e-04, 9.1950e-04, 9.0419e-04, 8.8911e-04, 8.7427e-04,\n",
      "        8.5966e-04, 8.4527e-04, 8.3111e-04, 8.1717e-04, 8.0345e-04, 7.8994e-04,\n",
      "        7.7664e-04, 7.6355e-04, 7.5067e-04, 7.3799e-04, 7.2551e-04, 7.1322e-04,\n",
      "        7.0113e-04, 6.8923e-04, 6.7752e-04, 6.6600e-04, 6.5465e-04, 6.4349e-04,\n",
      "        6.3250e-04, 6.2169e-04, 6.1106e-04, 6.0059e-04, 5.9029e-04, 5.8015e-04,\n",
      "        5.7018e-04, 5.6036e-04, 5.5071e-04, 5.4121e-04, 5.3186e-04, 5.2266e-04,\n",
      "        5.1362e-04, 5.0472e-04, 4.9596e-04, 4.8734e-04, 4.7887e-04, 4.7053e-04,\n",
      "        4.6233e-04, 4.5426e-04, 4.4633e-04, 4.3852e-04, 4.3084e-04, 4.2329e-04,\n",
      "        4.1586e-04, 4.0855e-04, 4.0137e-04, 3.9430e-04, 3.8735e-04, 3.8051e-04,\n",
      "        3.7379e-04, 3.6718e-04, 3.6067e-04, 3.5428e-04, 3.4799e-04, 3.4181e-04,\n",
      "        3.3573e-04, 3.2975e-04, 3.2387e-04, 3.1809e-04, 3.1240e-04, 3.0682e-04,\n",
      "        3.0132e-04, 2.9592e-04, 2.9061e-04, 2.8539e-04, 2.8025e-04, 2.7521e-04,\n",
      "        2.7024e-04, 2.6537e-04, 2.6057e-04, 2.5586e-04, 2.5123e-04, 2.4667e-04,\n",
      "        2.4220e-04, 2.3780e-04, 2.3347e-04, 2.2922e-04, 2.2504e-04, 2.2094e-04,\n",
      "        2.1690e-04, 2.1293e-04, 2.0904e-04, 2.0520e-04, 2.0144e-04, 1.9774e-04,\n",
      "        1.9410e-04, 1.9053e-04, 1.8702e-04, 1.8357e-04, 1.8018e-04, 1.7685e-04,\n",
      "        1.7358e-04, 1.7036e-04, 1.6720e-04, 1.6410e-04, 1.6105e-04, 1.5805e-04,\n",
      "        1.5511e-04, 1.5222e-04, 1.4937e-04, 1.4658e-04, 1.4384e-04, 1.4115e-04,\n",
      "        1.3850e-04, 1.3590e-04, 1.3335e-04, 1.3084e-04, 1.2838e-04, 1.2596e-04,\n",
      "        1.2358e-04, 1.2125e-04, 1.1896e-04, 1.1671e-04, 1.1450e-04, 1.1232e-04,\n",
      "        1.1019e-04, 1.0810e-04, 1.0604e-04, 1.0402e-04, 1.0204e-04, 1.0009e-04,\n",
      "        9.8180e-05, 9.6302e-05, 9.4459e-05, 9.2649e-05, 9.0871e-05, 8.9126e-05,\n",
      "        8.7413e-05, 8.5731e-05, 8.4080e-05, 8.2458e-05, 8.0867e-05, 7.9304e-05,\n",
      "        7.7770e-05, 7.6264e-05, 7.4786e-05, 7.3335e-05, 7.1911e-05, 7.0513e-05,\n",
      "        6.9140e-05, 6.7793e-05, 6.6471e-05, 6.5173e-05, 6.3900e-05, 6.2650e-05,\n",
      "        6.1423e-05, 6.0219e-05, 5.9038e-05, 5.7878e-05, 5.6740e-05, 5.5623e-05,\n",
      "        5.4527e-05, 5.3452e-05, 5.2397e-05, 5.1361e-05, 5.0345e-05, 4.9349e-05,\n",
      "        4.8370e-05, 4.7411e-05, 4.6469e-05, 4.5545e-05, 4.4639e-05, 4.3750e-05,\n",
      "        4.2877e-05, 4.2022e-05, 4.1182e-05, 4.0358e-05], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- EPOCH 1 --------------------\n",
      "\n",
      "----------Training...----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/storage/cmarnold/miniconda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at t5-base were not used when initializing T5EncoderModel: ['decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.final_layer_norm.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight']\n",
      "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------Validation...----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                             | 0/165917 [00:02<?, ?it/s]\u001b[A\n",
      "4it [02:32, 38.20s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 103\u001b[0m\n\u001b[1;32m    100\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(imagen\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mOPTIM_LR)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Train the MinImagen instance\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m \u001b[43mMinimagenTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimagen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/cmarnold/ASRS-Diffusion/training.py:391\u001b[0m, in \u001b[0;36mMinimagenTrain\u001b[0;34m(timestamp, args, unets, imagen, train_dataloader, valid_dataloader, training_dir, optimizer, timeout)\u001b[0m\n\u001b[1;32m    389\u001b[0m running_train_loss \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(unets))]\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mTraining...\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_num, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_dataloader)):\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _Timeout(timeout):\n\u001b[1;32m    394\u001b[0m             \u001b[38;5;66;03m# If batch is empty, move on to the next one\u001b[39;00m\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/site-packages/torch/utils/data/dataset.py:295\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/storage/cmarnold/ASRS-Diffusion/training.py:221\u001b[0m, in \u001b[0;36mMinimagenDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(idx):\n\u001b[1;32m    219\u001b[0m     idx \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m--> 221\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43m_fetch_single_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murls\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/storage/cmarnold/ASRS-Diffusion/training.py:132\u001b[0m, in \u001b[0;36m_fetch_single_image\u001b[0;34m(image_url, timeout, retries)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     request \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    128\u001b[0m         image_url,\n\u001b[1;32m    129\u001b[0m         data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    130\u001b[0m         headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser-agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT},\n\u001b[1;32m    131\u001b[0m     )\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    133\u001b[0m         image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(req\u001b[38;5;241m.\u001b[39mread()))\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m         \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/http/client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   1280\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/http/client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1328\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/http/client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1277\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/http/client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1035\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1037\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m \n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1043\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/http/client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/http/client.py:1447\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1447\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m   1450\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/http/client.py:941\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[1;32m    940\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[0;32m--> 941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/storage/cmarnold/miniconda/lib/python3.10/socket.py:833\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m    832\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m--> 833\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m    835\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import torch.utils.data\n",
    "from torch import optim\n",
    "\n",
    "from Imagen import Imagen\n",
    "from Unet import Unet, Base, Super, BaseTest, SuperTest\n",
    "from generate import load_minimagen, load_params\n",
    "from t5 import get_encoded_dim\n",
    "from training import get_minimagen_parser, ConceptualCaptions, get_minimagen_dl_opts, \\\n",
    "    create_directory, get_model_params, get_model_size, save_training_info, get_default_args, MinimagenTrain, \\\n",
    "    load_restart_training_parameters, load_testing_parameters\n",
    "\n",
    "# Get device\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Command line argument parser. See `training.get_minimagen_parser()`.\n",
    "parser = get_minimagen_parser()\n",
    "# Add argument for when using `main.py`\n",
    "parser.add_argument(\"-ts\", \"--TIMESTAMP\", dest=\"timestamp\", help=\"Timestamp for training directory\", type=str,\n",
    "                             default=None)\n",
    "args = parser.parse_args([\"-n\", \"0\"])\n",
    "print(args)\n",
    "timestamp = args.timestamp\n",
    "\n",
    "# Get training timestamp for when running train.py as main rather than via main.py\n",
    "if timestamp is None:\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Create training directory\n",
    "dir_path = f\"./training_{timestamp}\"\n",
    "training_dir = create_directory(dir_path)\n",
    "\n",
    "# If loading from a parameters/training directory\n",
    "if args.RESTART_DIRECTORY is not None:\n",
    "    args = load_restart_training_parameters(args)\n",
    "elif args.PARAMETERS is not None:\n",
    "    args = load_restart_training_parameters(args, justparams=True)\n",
    "\n",
    "# If testing, lower parameter values to lower computational load and also to lower amount of data being used.\n",
    "if args.TESTING:\n",
    "    args = load_testing_parameters(args)\n",
    "    train_dataset, valid_dataset = ConceptualCaptions(args, smalldata=True)\n",
    "else:\n",
    "    train_dataset, valid_dataset = ConceptualCaptions(args, smalldata=False)\n",
    "\n",
    "# Create dataloaders\n",
    "dl_opts = {**get_minimagen_dl_opts(device), 'batch_size': args.BATCH_SIZE, 'num_workers': args.NUM_WORKERS}\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, **dl_opts)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, **dl_opts)\n",
    "\n",
    "# Create Unets\n",
    "if args.RESTART_DIRECTORY is None:\n",
    "    imagen_params = dict(\n",
    "        image_sizes=(int(args.IMG_SIDE_LEN / 2), args.IMG_SIDE_LEN),\n",
    "        timesteps=args.TIMESTEPS,\n",
    "        cond_drop_prob=0.15,\n",
    "        text_encoder_name=args.T5_NAME\n",
    "    )\n",
    "\n",
    "    # If not loading a training from a checkpoint\n",
    "    if args.TESTING:\n",
    "        # If testing, use tiny MinImagen for low computational load\n",
    "        unets_params = [get_default_args(BaseTest), get_default_args(SuperTest)]\n",
    "\n",
    "    # Else if not loading Unet/Imagen settings from a config (parameters) folder, use defaults\n",
    "    elif not args.PARAMETERS:\n",
    "        # If no parameters provided, use params from minimagen.Imagen.Base and minimagen.Imagen.Super built-in classes\n",
    "        unets_params = [get_default_args(Base), get_default_args(Super)]\n",
    "\n",
    "    # Else load unet/Imagen configs from config (parameters) folder (override imagen+params)\n",
    "    else:\n",
    "        # If parameters are provided, load them\n",
    "        unets_params, imagen_params = get_model_params(args.PARAMETERS)\n",
    "\n",
    "    # Create Unets accoridng to unets_params\n",
    "    unets = [Unet(**unet_params).to(device) for unet_params in unets_params]\n",
    "\n",
    "    # Create Imagen from UNets with specified imagen parameters\n",
    "    imagen = Imagen(unets=unets, **imagen_params).to(device)\n",
    "else:\n",
    "    # If training is being resumed from a previous one, load all relevant models/info (load config AND state dicts)\n",
    "    orig_train_dir = os.path.join(os.getcwd(), args.RESTART_DIRECTORY)\n",
    "    unets_params, imagen_params = load_params(orig_train_dir)\n",
    "    imagen = load_minimagen(orig_train_dir).to(device)\n",
    "    unets = imagen.unets\n",
    "\n",
    "# Fill in unspecified arguments with defaults for complete config (parameters) file\n",
    "unets_params = [{**get_default_args(Unet), **i} for i in unets_params]\n",
    "imagen_params = {**get_default_args(Imagen), **imagen_params}\n",
    "\n",
    "# Get the size of the Imagen model in megabytes\n",
    "model_size_MB = get_model_size(imagen)\n",
    "\n",
    "# Save all training info (config files, model size, etc.)\n",
    "save_training_info(args, timestamp, unets_params, imagen_params, model_size_MB, training_dir)\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = optim.Adam(imagen.parameters(), lr=args.OPTIM_LR)\n",
    "\n",
    "# Train the MinImagen instance\n",
    "MinimagenTrain(timestamp, args, unets, imagen, train_dataloader, valid_dataloader, training_dir, optimizer, timeout=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e5c54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "38cf3a2657c4530458a1d5b90a9ba637718c74089d900d5938397f33b4197fc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
