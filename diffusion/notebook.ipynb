{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3500/3500 [2:01:51<00:00,  2.09s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2919 files retrieved in the \"train\" split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [53:51<00:00,  3.59s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710 files retrieved in the \"validation\" split.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import io\n",
    "import urllib\n",
    "from matplotlib import pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from datasets.utils.file_utils import get_datasets_user_agent\n",
    "import PIL.Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "\n",
    "USER_AGENT = get_datasets_user_agent()\n",
    "\n",
    "dir_path = \"dataset\"\n",
    "images_dir = \"images\"\n",
    "filepath_label = 'filepath'\n",
    "\n",
    "train_num = 3500 # Expect 15% of these images to not download\n",
    "valid_num = 900  # Expect 15% of these images to not download\n",
    "\n",
    "def get_img(url, retries=2):\n",
    "    for _ in range(retries + 1):\n",
    "            try:\n",
    "                request = urllib.request.Request(url, data=None, headers={'user-agent': USER_AGENT})\n",
    "                with urllib.request.urlopen(request) as req:\n",
    "                    image = PIL.Image.open(io.BytesIO(req.read()))\n",
    "                break\n",
    "            except:\n",
    "                image = None\n",
    "    \n",
    "    return image\n",
    "\n",
    "def load_data(key, df, num):\n",
    "    count = 0\n",
    "    for i in tqdm(range(num)):\n",
    "        if not df[key][filepath_label][i]:\n",
    "            pass\n",
    "\n",
    "        elif df[key][filepath_label][i] == \"null\":\n",
    "            url = df[key]['image_url'][i]\n",
    "\n",
    "            image = get_img(url)\n",
    "            if not image is None:\n",
    "                filepath = os.path.join(dir_path, images_dir, f'{key}_{i}.jpg')\n",
    "                try:\n",
    "                    image.save(filepath)\n",
    "                    df[key][filepath_label][i] = filepath\n",
    "                    count += 1\n",
    "                except:\n",
    "                    df[key][filepath_label][i] = None\n",
    "            else:\n",
    "                df[key][filepath_label][i] = None\n",
    "                #print(f'Could not fetch index {i}!')\n",
    "\n",
    "        else:\n",
    "            count += 1\n",
    "\n",
    "    print(f'{count} files retrieved in the \"{key}\" split.')\n",
    "    return df\n",
    "\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "    os.makedirs(os.path.join(dir_path, images_dir))\n",
    "\n",
    "    dset = load_dataset(\"conceptual_captions\")\n",
    "\n",
    "    filepaths = [\"null\"] * len(dset['train'])\n",
    "    dset['train'] = dset['train'].add_column(filepath_label, filepaths)\n",
    "\n",
    "    filepaths = [\"null\"] * len(dset['validation'])\n",
    "    dset['validation'] = dset['validation'].add_column(filepath_label, filepaths)\n",
    "\n",
    "    df_train = dset['train'].to_pandas()\n",
    "    df_valid = dset['validation'].to_pandas()\n",
    "\n",
    "    df = {\n",
    "        'train': df_train,\n",
    "        'validation': df_valid\n",
    "          }\n",
    "\n",
    "    with open(os.path.join(dir_path, 'df.pkl'), 'wb') as handle:\n",
    "        pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(os.path.join(dir_path, 'df.pkl'), 'rb') as handle:\n",
    "    df = pickle.load(handle)\n",
    "\n",
    "df = load_data('train', df, train_num)\n",
    "df = load_data('validation', df, valid_num)\n",
    "\n",
    "with open(os.path.join(dir_path, 'df.pkl'), 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#image = transforms.Compose([transforms.ToTensor(), utils.Rescale(64)])(image)\n",
    "#plt.figure(figsize=(8, 8))\n",
    "#plt.imshow(image.permute(1, 2, 0))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/archives/fgvc-aircraft-2013b.tar.gz to aircraft/fgvc-aircraft-2013b.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f29bd799eb4352bc5dcce90568566a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2753340328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting aircraft/fgvc-aircraft-2013b.tar.gz to aircraft\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset FGVCAircraft\n",
       "    Number of datapoints: 6667\n",
       "    Root location: aircraft"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import io\n",
    "import urllib\n",
    "from matplotlib import pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from datasets.utils.file_utils import get_datasets_user_agent\n",
    "import PIL.Image\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "\n",
    "dir_path = 'aircraft'\n",
    "\n",
    "datasets.FGVCAircraft(dir_path, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9008 --control=9006 --hb=9005 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"4dc3873a-42f8-4964-aede-eddabd0fe598\" --shell=9007 --transport=\"tcp\" --iopub=9009 --f=/afs/csail.mit.edu/u/c/cmarnold/.local/share/jupyter/runtime/kernel-v2-24054TKhKeSZou3vc.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/cmarnold/miniconda/envs/ml/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3468: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "encoder = T5EncoderModel.from_pretrained('t5-small')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
